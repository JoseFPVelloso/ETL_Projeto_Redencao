{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Bibliotecas importadas\n",
      "‚úì An√°lise iniciada em: 11/11/2025 15:59:02\n",
      "\n",
      "================================================================================\n",
      "DEFINIR PER√çODO DO RELAT√ìRIO\n",
      "================================================================================\n",
      "\n",
      "‚úì Per√≠odo selecionado: 01/10/2025 a 31/10/2025\n",
      "\n",
      "================================================================================\n",
      "Per√≠odo: 01/10/2025 a 31/10/2025\n",
      "  ‚Ä¢ Dias: 31\n",
      "  ‚Ä¢ Per√≠odos por dia: 2 (Manh√£ e Tarde)\n",
      "  ‚Ä¢ Total de per√≠odos: 62\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SELE√á√ÉO DO ARQUIVO RAW\n",
      "================================================================================\n",
      "üìÇ Pasta raw: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\data\\raw\n",
      "\n",
      "üìÅ Arquivos dispon√≠veis (mais recentes primeiro):\n",
      "  1. Contagem_diaria_centro - Padronizada.xlsx\n",
      "     Modificado em: 10/11/2025 18:58\n",
      "\n",
      "  2. Contagem di√°ria - Compilado.xlsx\n",
      "     Modificado em: 07/11/2025 11:51\n",
      "\n",
      "  3. CONTAGEM 2025 - CnR.xlsx\n",
      "     Modificado em: 06/11/2025 12:37\n",
      "\n",
      "  4. RelatorioCidadaoVinculado.xlsx\n",
      "     Modificado em: 05/11/2025 16:38\n",
      "\n",
      "  5. CidadaosVinculadosXBeneficios.xlsx\n",
      "     Modificado em: 05/11/2025 10:42\n",
      "\n",
      "  6. Base Okuhara Kohei.xlsx\n",
      "     Modificado em: 21/10/2025 18:54\n",
      "\n",
      "  7. nomes_Abordados.xlsx\n",
      "     Modificado em: 21/10/2025 17:51\n",
      "\n",
      "  8. Base Tablet.xlsx\n",
      "     Modificado em: 21/10/2025 17:48\n",
      "\n",
      "================================================================================\n",
      "‚úì Arquivo selecionado: CONTAGEM 2025 - CnR.xlsx\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CARREGANDO DADOS RAW\n",
      "================================================================================\n",
      "‚úì Arquivo carregado: CONTAGEM 2025 - CnR.xlsx\n",
      "‚úì Total de registros: 1,943\n",
      "\n",
      "Colunas dispon√≠veis:\n",
      "  - Data\n",
      "  - Equipe\n",
      "  - Logradouro\n",
      "  - Per√≠odo\n",
      "  - Quantidade\n",
      "\n",
      "================================================================================\n",
      "PREPARANDO DADOS\n",
      "================================================================================\n",
      "‚úì Campo 'Data' convertido para datetime\n",
      "‚úì Campo 'Quantidade' convertido para num√©rico\n",
      "‚úì Campo 'Logradouro' limpo\n",
      "‚úì Registros preparados: 1,943\n",
      "\n",
      "Regi√µes encontradas:\n",
      "  - Complexo Okuhara Koei (9 logradouros)\n",
      "  - Glic√©rio (2 logradouros)\n",
      "  - Parque Dom Pedro II (2 logradouros)\n",
      "  - Pra√ßa Roosevelt (1 logradouros)\n",
      "\n",
      "Per√≠odos encontrados (originais):\n",
      "  - 10h\n",
      "  - 15h\n",
      "\n",
      "Per√≠odos padronizados:\n",
      "  - Manh√£\n",
      "  - Tarde\n",
      "\n",
      "‚úì Registros ap√≥s limpeza: 1,943\n",
      "\n",
      "================================================================================\n",
      "FILTRANDO PER√çODO\n",
      "================================================================================\n",
      "Data in√≠cio: 2025-10-01\n",
      "Data fim: 2025-10-31\n",
      "Dias no per√≠odo: 31\n",
      "‚úì Registros no per√≠odo: 952\n",
      "  Logradouros √∫nicos: 13\n",
      "  Regi√µes √∫nicas: 3\n",
      "  Per√≠odos √∫nicos: ['Manh√£', 'Tarde']\n",
      "\n",
      "================================================================================\n",
      "CALCULANDO SOMA TOTAL POR REGI√ÉO\n",
      "================================================================================\n",
      "‚úì Regi√µes ordenadas por soma total:\n",
      "  Parque Dom Pedro II: 3,191 pessoas\n",
      "  Complexo Okuhara Koei: 2,746 pessoas\n",
      "  Glic√©rio: 1,472 pessoas\n",
      "\n",
      "================================================================================\n",
      "AGRUPANDO POR REGI√ÉO E LOGRADOURO\n",
      "================================================================================\n",
      "\n",
      "‚úì Calculando m√©dias por per√≠odo para cada logradouro...\n",
      "‚úì Agrupamento conclu√≠do\n",
      "  Total de logradouros: 13\n",
      "  Total de regi√µes: 3\n",
      "\n",
      "================================================================================\n",
      "CRIANDO RANKINGS DE M√âDIA POR REGI√ÉO\n",
      "================================================================================\n",
      "\n",
      "‚úì Regi√£o: Parque Dom Pedro II\n",
      "  Total de logradouros: 2\n",
      "  Maior m√©dia: 42.18\n",
      "  Menor m√©dia: 9.29\n",
      "\n",
      "‚úì Regi√£o: Complexo Okuhara Koei\n",
      "  Total de logradouros: 9\n",
      "  Maior m√©dia: 12.61\n",
      "  Menor m√©dia: 2.71\n",
      "\n",
      "‚úì Regi√£o: Glic√©rio\n",
      "  Total de logradouros: 2\n",
      "  Maior m√©dia: 13.97\n",
      "  Menor m√©dia: 9.77\n",
      "\n",
      "================================================================================\n",
      "CRIANDO ABAS NO EXCEL POR REGI√ÉO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processando Regi√£o: Parque Dom Pedro II\n",
      "================================================================================\n",
      "‚úì Aba 'Rank M√©dia Parque Dom Pedro II' criada (2 logradouros)\n",
      "  [1/2] ‚úì 'Pra√ßa Fernando Costa' (31 dias)\n",
      "  [2/2] ‚úì 'Viaduto Ant√¥nio Nakashima (emba' (31 dias)\n",
      "\n",
      "================================================================================\n",
      "Processando Regi√£o: Complexo Okuhara Koei\n",
      "================================================================================\n",
      "‚úì Aba 'M√©dia Complexo Okuhara Koei' criada (9 logradouros)\n",
      "  [1/9] ‚úì 'Rua Minas Gerais (Antena Grill)' (31 dias)\n",
      "  [2/9] ‚úì 'Viaduto Okuhara- Fitinha (later' (31 dias)\n",
      "  [3/9] ‚úì 'Avenida Paulista' (31 dias)\n",
      "  [4/9] ‚úì 'Rua Vinicius de Moraes (Pens√£o ' (31 dias)\n",
      "  [5/9] ‚úì 'Pra√ßa Dr. Clemente Ferreira (Su' (31 dias)\n",
      "  [6/9] ‚úì 'Avenida Rebou√ßas (Rampa)' (31 dias)\n",
      "  [7/9] ‚úì 'Pra√ßa Jos√© Molina (Floresta)' (31 dias)\n",
      "  [8/9] ‚úì 'Rua P. Enerst Marcus' (31 dias)\n",
      "  [9/9] ‚úì 'Avenida Pacaembu - Tunel Noite ' (31 dias)\n",
      "\n",
      "================================================================================\n",
      "Processando Regi√£o: Glic√©rio\n",
      "================================================================================\n",
      "‚úì Aba 'Rank M√©dia Glic√©rio' criada (2 logradouros)\n",
      "  [1/2] ‚úì 'Avenida Prefeito Passos, 200' (31 dias)\n",
      "  [2/2] ‚úì 'Rua Ant√¥nio de S√° - bosque urba' (31 dias)\n",
      "\n",
      "================================================================================\n",
      "‚úì Arquivo criado: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\top10_raw_analise_por_regiao.xlsx\n",
      "  Total de abas criadas: 16\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESUMO EXECUTIVO\n",
      "================================================================================\n",
      "\n",
      "AN√ÅLISE: RANKINGS POR REGI√ÉO (VERS√ÉO RAW)\n",
      "\n",
      "ARQUIVO ANALISADO:\n",
      "‚Ä¢ CONTAGEM 2025 - CnR.xlsx\n",
      "\n",
      "PER√çODO:\n",
      "‚Ä¢ De: 01/10/2025\n",
      "‚Ä¢ At√©: 31/10/2025\n",
      "‚Ä¢ Total de dias: 31\n",
      "‚Ä¢ Total de per√≠odos: 62 (31 dias √ó 2 per√≠odos)\n",
      "\n",
      "METODOLOGIA:\n",
      "‚Ä¢ Fonte: Planilha RAW (data/raw)\n",
      "‚Ä¢ Estrutura: Data, Equipe, Logradouro, Per√≠odo, Quantidade\n",
      "‚Ä¢ Per√≠odos: 10h (Manh√£) e 15h (Tarde)\n",
      "‚Ä¢ Extra√ß√£o de Regi√£o: Tudo antes do primeiro \" - \"\n",
      "‚Ä¢ Agrupamento: Por Regi√£o e depois por Logradouro\n",
      "‚Ä¢ Ordena√ß√£o das Regi√µes: Por soma total de pessoas (decrescente)\n",
      "\n",
      "C√ÅLCULOS:\n",
      "‚Ä¢ Soma pessoas: Soma de Quantidade de todos os per√≠odos\n",
      "‚Ä¢ M√©dia pessoas: Soma pessoas √∑ 62 per√≠odos\n",
      "‚Ä¢ M√©dia por per√≠odo: Soma do per√≠odo √∑ 31 dias\n",
      "\n",
      "DADOS PROCESSADOS:\n",
      "‚Ä¢ Registros totais no per√≠odo: 952\n",
      "‚Ä¢ Regi√µes encontradas: 3\n",
      "‚Ä¢ Logradouros √∫nicos: 13\n",
      "\n",
      "RESUMO POR REGI√ÉO:\n",
      "\n",
      "  ‚Ä¢ Parque Dom Pedro II:\n",
      "    - Logradouros: 2\n",
      "    - Soma total: 3,191 pessoas\n",
      "\n",
      "  ‚Ä¢ Complexo Okuhara Koei:\n",
      "    - Logradouros: 9\n",
      "    - Soma total: 2,746 pessoas\n",
      "\n",
      "  ‚Ä¢ Glic√©rio:\n",
      "    - Logradouros: 2\n",
      "    - Soma total: 1,472 pessoas\n",
      "\n",
      "ARQUIVO GERADO:\n",
      "‚úì c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\top10_raw_analise_por_regiao.xlsx\n",
      "\n",
      "ESTRUTURA DAS ABAS:\n",
      "Para cada regi√£o (ordenadas por soma total):\n",
      "  1. Rank M√©dia [Regi√£o] - Todos os logradouros ordenados por m√©dia\n",
      "  2. Abas individuais de cada logradouro (na ordem do rank, com TODAS as datas)\n",
      "\n",
      "REGI√ÉO COM MAIOR SOMA TOTAL:\n",
      "‚Ä¢ Regi√£o: Parque Dom Pedro II\n",
      "‚Ä¢ Soma total: 3,191 pessoas\n",
      "‚Ä¢ Logradouros: 2\n",
      "\n",
      "\n",
      "TOP 1 DE CADA REGI√ÉO (POR M√âDIA):\n",
      "================================================================================\n",
      "\n",
      "Parque Dom Pedro II:\n",
      "  ‚Ä¢ Logradouro: Parque Dom Pedro II - Pra√ßa Fernando Costa\n",
      "  ‚Ä¢ M√©dia pessoas: 42.18\n",
      "  ‚Ä¢ Manh√£: 44.35 | Tarde: 40.00\n",
      "\n",
      "Complexo Okuhara Koei:\n",
      "  ‚Ä¢ Logradouro: Complexo Okuhara Koei - Rua Minas Gerais (Antena Grill)\n",
      "  ‚Ä¢ M√©dia pessoas: 12.61\n",
      "  ‚Ä¢ Manh√£: 11.68 | Tarde: 13.55\n",
      "\n",
      "Glic√©rio:\n",
      "  ‚Ä¢ Logradouro: Glic√©rio - Avenida Prefeito Passos, 200\n",
      "  ‚Ä¢ M√©dia pessoas: 13.97\n",
      "  ‚Ä¢ Manh√£: 14.71 | Tarde: 13.23\n",
      "\n",
      "================================================================================\n",
      "‚úì AN√ÅLISE CONCLU√çDA!\n",
      "‚úì 11/11/2025 15:59:12\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# An√°lise dos 10 Logradouros - VERS√ÉO RAW\n",
    "# Base: Planilha RAW (data/raw)\n",
    "# Estrutura: Data, Equipe, Logradouro, Per√≠odo, Quantidade\n",
    "# Per√≠odos: 10h (Manh√£) e 15h (Tarde)\n",
    "# Per√≠odo: Solicitado ao usu√°rio\n",
    "\n",
    "# %% [markdown]\n",
    "# # 1. Configura√ß√£o Inicial\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas\")\n",
    "print(f\"‚úì An√°lise iniciada em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 2. Definir Per√≠odo de An√°lise\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEFINIR PER√çODO DO RELAT√ìRIO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "data_inicio_str = input(\"\\nDigite a DATA INICIAL (dd/mm/aaaa): \")\n",
    "data_fim_str = input(\"Digite a DATA FINAL (dd/mm/aaaa): \")\n",
    "\n",
    "# Converter datas\n",
    "try:\n",
    "    data_inicio_dt = datetime.strptime(data_inicio_str, \"%d/%m/%Y\")\n",
    "    data_fim_dt = datetime.strptime(data_fim_str, \"%d/%m/%Y\")\n",
    "    \n",
    "    # Converter para formato string usado nos filtros\n",
    "    data_inicio = data_inicio_dt.strftime('%Y-%m-%d')\n",
    "    data_fim = data_fim_dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"\\n‚úì Per√≠odo selecionado: {data_inicio_dt.strftime('%d/%m/%Y')} a {data_fim_dt.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    # Calcular quantidade de dias\n",
    "    dias_periodo = (data_fim_dt - data_inicio_dt).days + 1\n",
    "    total_periodos = dias_periodo * 2  # 2 per√≠odos por dia (Manh√£ e Tarde)\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Per√≠odo: {data_inicio_dt.strftime('%d/%m/%Y')} a {data_fim_dt.strftime('%d/%m/%Y')}\")\n",
    "    print(f\"  ‚Ä¢ Dias: {dias_periodo}\")\n",
    "    print(f\"  ‚Ä¢ Per√≠odos por dia: 2 (Manh√£ e Tarde)\")\n",
    "    print(f\"  ‚Ä¢ Total de per√≠odos: {total_periodos}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "except ValueError:\n",
    "    print(\"‚ùå Formato de data inv√°lido! Use dd/mm/aaaa\")\n",
    "    raise Exception(\"Formato de data inv√°lido\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 3. Selecionar Arquivo RAW\n",
    "\n",
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SELE√á√ÉO DO ARQUIVO RAW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detectar raiz do projeto\n",
    "script_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "if script_dir.name == 'notebooks':\n",
    "    project_root = script_dir.parent\n",
    "elif script_dir.name == 'etl':\n",
    "    project_root = script_dir.parent.parent\n",
    "else:\n",
    "    project_root = script_dir\n",
    "\n",
    "pasta_raw = project_root / 'data' / 'raw'\n",
    "print(f\"üìÇ Pasta raw: {pasta_raw}\")\n",
    "\n",
    "# Listar arquivos dispon√≠veis\n",
    "arquivos_disponiveis = sorted(list(pasta_raw.glob('*.xlsx')), \n",
    "                               key=lambda x: x.stat().st_mtime, \n",
    "                               reverse=True)\n",
    "\n",
    "if arquivos_disponiveis:\n",
    "    print(f\"\\nüìÅ Arquivos dispon√≠veis (mais recentes primeiro):\")\n",
    "    for i, arq in enumerate(arquivos_disponiveis, 1):\n",
    "        modificado = datetime.fromtimestamp(arq.stat().st_mtime).strftime('%d/%m/%Y %H:%M')\n",
    "        print(f\"  {i}. {arq.name}\")\n",
    "        print(f\"     Modificado em: {modificado}\\n\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    selecao = int(input(\"Digite o n√∫mero do arquivo que deseja analisar: \"))\n",
    "    arquivo_selecionado = arquivos_disponiveis[selecao - 1]\n",
    "    print(f\"‚úì Arquivo selecionado: {arquivo_selecionado.name}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Nenhum arquivo .xlsx encontrado em '{pasta_raw}'\")\n",
    "    raise FileNotFoundError(f\"Nenhum arquivo em {pasta_raw}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %% [markdown]\n",
    "# # 4. Carregar Dados RAW\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CARREGANDO DADOS RAW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(arquivo_selecionado)\n",
    "    print(f\"‚úì Arquivo carregado: {arquivo_selecionado.name}\")\n",
    "    print(f\"‚úì Total de registros: {len(df):,}\")\n",
    "    print(f\"\\nColunas dispon√≠veis:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Verificar campos necess√°rios\n",
    "    campos_necessarios = ['Data', 'Logradouro', 'Per√≠odo', 'Quantidade']\n",
    "    campos_faltando = [c for c in campos_necessarios if c not in df.columns]\n",
    "    \n",
    "    if campos_faltando:\n",
    "        print(f\"\\n‚úó ERRO: Campos faltando: {campos_faltando}\")\n",
    "        raise KeyError(\"Campos necess√°rios n√£o encontrados\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó ERRO ao carregar arquivo: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# # 5. Preparar Dados\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPARANDO DADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Converter data\n",
    "df['Data'] = pd.to_datetime(df['Data'], errors='coerce')\n",
    "\n",
    "# Garantir que Quantidade seja num√©rico\n",
    "df['Quantidade'] = pd.to_numeric(df['Quantidade'], errors='coerce').fillna(0)\n",
    "\n",
    "# Limpar espa√ßos em branco no Logradouro e Per√≠odo\n",
    "df['Logradouro'] = df['Logradouro'].astype(str).str.strip()\n",
    "df['Per√≠odo'] = df['Per√≠odo'].astype(str).str.strip()\n",
    "\n",
    "print(f\"‚úì Campo 'Data' convertido para datetime\")\n",
    "print(f\"‚úì Campo 'Quantidade' convertido para num√©rico\")\n",
    "print(f\"‚úì Campo 'Logradouro' limpo\")\n",
    "print(f\"‚úì Registros preparados: {len(df):,}\")\n",
    "\n",
    "# Extrair regi√£o do logradouro (tudo antes do primeiro \" - \")\n",
    "df['Regi√£o'] = df['Logradouro'].str.split(' - ', n=1).str[0].str.strip()\n",
    "\n",
    "print(f\"\\nRegi√µes encontradas:\")\n",
    "regioes_unicas = sorted(df['Regi√£o'].unique())\n",
    "for regiao in regioes_unicas:\n",
    "    qtd_log = df[df['Regi√£o'] == regiao]['Logradouro'].nunique()\n",
    "    print(f\"  - {regiao} ({qtd_log} logradouros)\")\n",
    "\n",
    "# Verificar per√≠odos √∫nicos ANTES do mapeamento\n",
    "print(f\"\\nPer√≠odos encontrados (originais):\")\n",
    "for periodo in sorted(df['Per√≠odo'].unique()):\n",
    "    print(f\"  - {periodo}\")\n",
    "\n",
    "# Mapear per√≠odos: 10h ‚Üí Manh√£, 15h ‚Üí Tarde\n",
    "mapeamento_periodos = {\n",
    "    '10h': 'Manh√£',\n",
    "    '15h': 'Tarde'\n",
    "}\n",
    "\n",
    "df['Per√≠odo_padrao'] = df['Per√≠odo'].map(mapeamento_periodos)\n",
    "\n",
    "# Verificar se h√° per√≠odos n√£o mapeados\n",
    "periodos_nao_mapeados = df[df['Per√≠odo_padrao'].isna()]['Per√≠odo'].unique()\n",
    "if len(periodos_nao_mapeados) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è ATEN√á√ÉO: Per√≠odos n√£o mapeados encontrados:\")\n",
    "    for periodo in periodos_nao_mapeados:\n",
    "        print(f\"  - '{periodo}'\")\n",
    "    print(f\"\\n   Esses registros ser√£o ignorados na an√°lise.\")\n",
    "    # Remover registros n√£o mapeados\n",
    "    df = df[df['Per√≠odo_padrao'].notna()].copy()\n",
    "\n",
    "print(f\"\\nPer√≠odos padronizados:\")\n",
    "for periodo in sorted(df['Per√≠odo_padrao'].unique()):\n",
    "    print(f\"  - {periodo}\")\n",
    "\n",
    "print(f\"\\n‚úì Registros ap√≥s limpeza: {len(df):,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 6. Filtrar Per√≠odo\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILTRANDO PER√çODO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filtrar per√≠odo\n",
    "df_periodo = df[\n",
    "    (df['Data'] >= data_inicio) & \n",
    "    (df['Data'] <= data_fim)\n",
    "].copy()\n",
    "\n",
    "print(f\"Data in√≠cio: {data_inicio}\")\n",
    "print(f\"Data fim: {data_fim}\")\n",
    "print(f\"Dias no per√≠odo: {dias_periodo}\")\n",
    "print(f\"‚úì Registros no per√≠odo: {len(df_periodo):,}\")\n",
    "print(f\"  Logradouros √∫nicos: {df_periodo['Logradouro'].nunique()}\")\n",
    "print(f\"  Regi√µes √∫nicas: {df_periodo['Regi√£o'].nunique()}\")\n",
    "print(f\"  Per√≠odos √∫nicos: {sorted(df_periodo['Per√≠odo_padrao'].unique())}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 7. Calcular Soma Total por Regi√£o (para ordena√ß√£o)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CALCULANDO SOMA TOTAL POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular soma total de pessoas por regi√£o\n",
    "soma_por_regiao = df_periodo.groupby('Regi√£o')['Quantidade'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(f\"‚úì Regi√µes ordenadas por soma total:\")\n",
    "for regiao, soma in soma_por_regiao.items():\n",
    "    print(f\"  {regiao}: {soma:,.0f} pessoas\")\n",
    "\n",
    "# Lista ordenada de regi√µes (ser√° usada para ordenar as abas)\n",
    "regioes_ordenadas = soma_por_regiao.index.tolist()\n",
    "\n",
    "# %% [markdown]\n",
    "# # 8. Agrupar por Regi√£o e Logradouro\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AGRUPANDO POR REGI√ÉO E LOGRADOURO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Agrupar por Regi√£o e Logradouro\n",
    "df_agrupado = df_periodo.groupby(['Regi√£o', 'Logradouro']).agg({\n",
    "    'Quantidade': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Renomear coluna\n",
    "df_agrupado.rename(columns={'Quantidade': 'Soma pessoas'}, inplace=True)\n",
    "\n",
    "# Calcular M√©dia pessoas (soma / total de per√≠odos)\n",
    "df_agrupado['M√©dia pessoas'] = df_agrupado['Soma pessoas'] / total_periodos\n",
    "\n",
    "# Para cada logradouro, calcular m√©dia por per√≠odo\n",
    "print(\"\\n‚úì Calculando m√©dias por per√≠odo para cada logradouro...\")\n",
    "\n",
    "medias_lista = []\n",
    "\n",
    "for idx, row in df_agrupado.iterrows():\n",
    "    regiao = row['Regi√£o']\n",
    "    logradouro = row['Logradouro']\n",
    "    \n",
    "    # Filtrar dados desse logradouro\n",
    "    df_log = df_periodo[df_periodo['Logradouro'] == logradouro].copy()\n",
    "    \n",
    "    # Agrupar por per√≠odo e somar\n",
    "    soma_por_periodo = df_log.groupby('Per√≠odo_padrao')['Quantidade'].sum()\n",
    "    \n",
    "    # Calcular m√©dia (dividir pela quantidade de dias)\n",
    "    media_manha = soma_por_periodo.get('Manh√£', 0) / dias_periodo\n",
    "    media_tarde = soma_por_periodo.get('Tarde', 0) / dias_periodo\n",
    "    \n",
    "    medias_lista.append({\n",
    "        'Regi√£o': regiao,\n",
    "        'Logradouro': logradouro,\n",
    "        'Soma pessoas': row['Soma pessoas'],\n",
    "        'M√©dia pessoas': row['M√©dia pessoas'],\n",
    "        'Manh√£': media_manha,\n",
    "        'Tarde': media_tarde\n",
    "    })\n",
    "\n",
    "df_completo = pd.DataFrame(medias_lista)\n",
    "\n",
    "print(f\"‚úì Agrupamento conclu√≠do\")\n",
    "print(f\"  Total de logradouros: {len(df_completo)}\")\n",
    "print(f\"  Total de regi√µes: {df_completo['Regi√£o'].nunique()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 9. Criar Rankings por Regi√£o (M√©dia)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRIANDO RANKINGS DE M√âDIA POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rankings_media = {}\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    df_regiao = df_completo[df_completo['Regi√£o'] == regiao].copy()\n",
    "    \n",
    "    # Ordenar por M√©dia pessoas (decrescente)\n",
    "    df_regiao = df_regiao.sort_values('M√©dia pessoas', ascending=False)\n",
    "    \n",
    "    rankings_media[regiao] = df_regiao\n",
    "    \n",
    "    print(f\"\\n‚úì Regi√£o: {regiao}\")\n",
    "    print(f\"  Total de logradouros: {len(df_regiao)}\")\n",
    "    print(f\"  Maior m√©dia: {df_regiao['M√©dia pessoas'].max():.2f}\")\n",
    "    print(f\"  Menor m√©dia: {df_regiao['M√©dia pessoas'].min():.2f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 10. Criar Abas no Excel\n",
    "\n",
    "# %%\n",
    "def limpar_nome_aba(nome):\n",
    "    \"\"\"Remove caracteres inv√°lidos para nomes de abas do Excel\"\"\"\n",
    "    # Caracteres inv√°lidos no Excel: : \\ / ? * [ ]\n",
    "    caracteres_invalidos = [':', '\\\\', '/', '?', '*', '[', ']']\n",
    "    nome_limpo = nome\n",
    "    for char in caracteres_invalidos:\n",
    "        nome_limpo = nome_limpo.replace(char, '-')\n",
    "    # Limitar a 31 caracteres\n",
    "    return nome_limpo[:31]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRIANDO ABAS NO EXCEL POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Caminho do arquivo de sa√≠da\n",
    "pasta_docs = project_root / 'docs'\n",
    "pasta_docs.mkdir(parents=True, exist_ok=True)\n",
    "output_file = pasta_docs / 'top10_raw_analise_por_regiao.xlsx'\n",
    "\n",
    "# Criar o arquivo Excel\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    \n",
    "    # Contador de abas para garantir nomes √∫nicos\n",
    "    nomes_abas_usados = {}\n",
    "    \n",
    "    # Para cada regi√£o (ordenadas por soma total)\n",
    "    for regiao in regioes_ordenadas:\n",
    "        \n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Processando Regi√£o: {regiao}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        # 1. ABA: Rank M√©dia [Regi√£o]\n",
    "        df_rank_media = rankings_media[regiao].copy()\n",
    "        df_rank_media_exportar = df_rank_media[[\n",
    "            'Logradouro', \n",
    "            'Soma pessoas', \n",
    "            'M√©dia pessoas',\n",
    "            'Manh√£',\n",
    "            'Tarde'\n",
    "        ]].copy()\n",
    "        df_rank_media_exportar.insert(0, '#', range(1, len(df_rank_media_exportar) + 1))\n",
    "        \n",
    "        # Nome da aba (limitar a 31 caracteres)\n",
    "        nome_aba_media = f\"Rank M√©dia {regiao}\"\n",
    "        if len(nome_aba_media) > 31:\n",
    "            nome_aba_media = f\"M√©dia {regiao}\"[:31]\n",
    "        \n",
    "        # Limpar caracteres inv√°lidos\n",
    "        nome_aba_media = limpar_nome_aba(nome_aba_media)\n",
    "        \n",
    "        # Garantir nome √∫nico\n",
    "        nome_aba_media_final = nome_aba_media\n",
    "        contador = 1\n",
    "        while nome_aba_media_final in nomes_abas_usados:\n",
    "            nome_aba_media_final = f\"{nome_aba_media[:28]}_{contador}\"\n",
    "            contador += 1\n",
    "        nomes_abas_usados[nome_aba_media_final] = True\n",
    "        \n",
    "        df_rank_media_exportar.to_excel(writer, sheet_name=nome_aba_media_final, index=False)\n",
    "        print(f\"‚úì Aba '{nome_aba_media_final}' criada ({len(df_rank_media_exportar)} logradouros)\")\n",
    "        \n",
    "        # 2. ABAS INDIVIDUAIS: Para cada logradouro do Rank M√©dia (NA ORDEM DO RANKING)\n",
    "        logradouros_ordenados = df_rank_media['Logradouro'].tolist()\n",
    "        \n",
    "        for idx, logradouro in enumerate(logradouros_ordenados, 1):\n",
    "            \n",
    "            # Filtrar dados originais para esse logradouro\n",
    "            df_detalhado = df_periodo[\n",
    "                df_periodo['Logradouro'] == logradouro\n",
    "            ].copy()\n",
    "            \n",
    "            # Criar pivot: transformar per√≠odos em colunas\n",
    "            df_pivot = df_detalhado.pivot_table(\n",
    "                index='Data',\n",
    "                columns='Per√≠odo_padrao',\n",
    "                values='Quantidade',\n",
    "                aggfunc='sum',\n",
    "                fill_value=0\n",
    "            ).reset_index()\n",
    "            \n",
    "            # PREENCHER DATAS FALTANTES\n",
    "            # Criar range completo de datas do per√≠odo\n",
    "            data_inicio_dt_range = pd.to_datetime(data_inicio)\n",
    "            data_fim_dt_range = pd.to_datetime(data_fim)\n",
    "            todas_datas = pd.date_range(start=data_inicio_dt_range, end=data_fim_dt_range, freq='D')\n",
    "            \n",
    "            # Criar DataFrame com todas as datas\n",
    "            df_todas_datas = pd.DataFrame({'Data': todas_datas})\n",
    "            \n",
    "            # Fazer merge para incluir datas faltantes\n",
    "            df_pivot = df_todas_datas.merge(df_pivot, on='Data', how='left')\n",
    "            \n",
    "            # Preencher valores faltantes com 0 (colunas de per√≠odo)\n",
    "            colunas_periodo = [col for col in df_pivot.columns if col != 'Data']\n",
    "            df_pivot[colunas_periodo] = df_pivot[colunas_periodo].fillna(0)\n",
    "            \n",
    "            # Garantir que todas as colunas de per√≠odo existam\n",
    "            for periodo in ['Manh√£', 'Tarde']:\n",
    "                if periodo not in df_pivot.columns:\n",
    "                    df_pivot[periodo] = 0\n",
    "            \n",
    "            # Preparar DataFrame para exporta√ß√£o na ordem correta\n",
    "            df_exportar = pd.DataFrame()\n",
    "            df_exportar['Logradouro'] = [logradouro] * len(df_pivot)\n",
    "            df_exportar['Data'] = df_pivot['Data'].dt.strftime('%d/%m/%Y')\n",
    "            df_exportar['Manh√£'] = df_pivot['Manh√£'].astype(int)\n",
    "            df_exportar['Tarde'] = df_pivot['Tarde'].astype(int)\n",
    "            \n",
    "            # Nome da aba (limitado a 31 caracteres)\n",
    "            # Extrair apenas o nome do logradouro (depois do \" - \")\n",
    "            if ' - ' in logradouro:\n",
    "                nome_logr_curto = logradouro.split(' - ', 1)[1]\n",
    "            else:\n",
    "                nome_logr_curto = logradouro\n",
    "            \n",
    "            # Limpar caracteres inv√°lidos\n",
    "            nome_aba = limpar_nome_aba(nome_logr_curto)\n",
    "            \n",
    "            # Garantir nome √∫nico de aba\n",
    "            nome_aba_final = nome_aba\n",
    "            contador = 1\n",
    "            while nome_aba_final in nomes_abas_usados:\n",
    "                sufixo = f\"_{contador}\"\n",
    "                nome_aba_final = nome_aba[:31-len(sufixo)] + sufixo\n",
    "                contador += 1\n",
    "            nomes_abas_usados[nome_aba_final] = True\n",
    "            \n",
    "            # Escrever aba\n",
    "            df_exportar.to_excel(writer, sheet_name=nome_aba_final, index=False)\n",
    "            print(f\"  [{idx}/{len(logradouros_ordenados)}] ‚úì '{nome_aba_final}' ({len(df_exportar)} dias)\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"‚úì Arquivo criado: {output_file}\")\n",
    "print(f\"  Total de abas criadas: {len(nomes_abas_usados)}\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 11. Resumo Executivo\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMO EXECUTIVO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Contar total de logradouros\n",
    "total_logradouros = df_completo['Logradouro'].nunique()\n",
    "total_regioes = len(regioes_ordenadas)\n",
    "\n",
    "# Resumo por regi√£o\n",
    "resumo_regioes = []\n",
    "for regiao in regioes_ordenadas:\n",
    "    qtd_logradouros = len(rankings_media[regiao])\n",
    "    soma_total = soma_por_regiao[regiao]\n",
    "    \n",
    "    resumo_regioes.append(f\"\"\"\n",
    "  ‚Ä¢ {regiao}:\n",
    "    - Logradouros: {qtd_logradouros}\n",
    "    - Soma total: {soma_total:,.0f} pessoas\"\"\")\n",
    "\n",
    "resumo_regioes_str = \"\\n\".join(resumo_regioes)\n",
    "\n",
    "print(f\"\"\"\n",
    "AN√ÅLISE: RANKINGS POR REGI√ÉO (VERS√ÉO RAW)\n",
    "\n",
    "ARQUIVO ANALISADO:\n",
    "‚Ä¢ {arquivo_selecionado.name}\n",
    "\n",
    "PER√çODO:\n",
    "‚Ä¢ De: {data_inicio_dt.strftime('%d/%m/%Y')}\n",
    "‚Ä¢ At√©: {data_fim_dt.strftime('%d/%m/%Y')}\n",
    "‚Ä¢ Total de dias: {dias_periodo}\n",
    "‚Ä¢ Total de per√≠odos: {total_periodos} ({dias_periodo} dias √ó 2 per√≠odos)\n",
    "\n",
    "METODOLOGIA:\n",
    "‚Ä¢ Fonte: Planilha RAW (data/raw)\n",
    "‚Ä¢ Estrutura: Data, Equipe, Logradouro, Per√≠odo, Quantidade\n",
    "‚Ä¢ Per√≠odos: 10h (Manh√£) e 15h (Tarde)\n",
    "‚Ä¢ Extra√ß√£o de Regi√£o: Tudo antes do primeiro \" - \"\n",
    "‚Ä¢ Agrupamento: Por Regi√£o e depois por Logradouro\n",
    "‚Ä¢ Ordena√ß√£o das Regi√µes: Por soma total de pessoas (decrescente)\n",
    "\n",
    "C√ÅLCULOS:\n",
    "‚Ä¢ Soma pessoas: Soma de Quantidade de todos os per√≠odos\n",
    "‚Ä¢ M√©dia pessoas: Soma pessoas √∑ {total_periodos} per√≠odos\n",
    "‚Ä¢ M√©dia por per√≠odo: Soma do per√≠odo √∑ {dias_periodo} dias\n",
    "\n",
    "DADOS PROCESSADOS:\n",
    "‚Ä¢ Registros totais no per√≠odo: {len(df_periodo):,}\n",
    "‚Ä¢ Regi√µes encontradas: {total_regioes}\n",
    "‚Ä¢ Logradouros √∫nicos: {total_logradouros}\n",
    "\n",
    "RESUMO POR REGI√ÉO:\n",
    "{resumo_regioes_str}\n",
    "\n",
    "ARQUIVO GERADO:\n",
    "‚úì {output_file}\n",
    "\n",
    "ESTRUTURA DAS ABAS:\n",
    "Para cada regi√£o (ordenadas por soma total):\n",
    "  1. Rank M√©dia [Regi√£o] - Todos os logradouros ordenados por m√©dia\n",
    "  2. Abas individuais de cada logradouro (na ordem do rank, com TODAS as datas)\n",
    "\n",
    "REGI√ÉO COM MAIOR SOMA TOTAL:\n",
    "‚Ä¢ Regi√£o: {regioes_ordenadas[0]}\n",
    "‚Ä¢ Soma total: {soma_por_regiao[regioes_ordenadas[0]]:,.0f} pessoas\n",
    "‚Ä¢ Logradouros: {len(rankings_media[regioes_ordenadas[0]])}\n",
    "\"\"\")\n",
    "\n",
    "# Top 1 de cada regi√£o\n",
    "print(f\"\\nTOP 1 DE CADA REGI√ÉO (POR M√âDIA):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    df_regiao = rankings_media[regiao]\n",
    "    if len(df_regiao) > 0:\n",
    "        top1 = df_regiao.iloc[0]\n",
    "        print(f\"\\n{regiao}:\")\n",
    "        print(f\"  ‚Ä¢ Logradouro: {top1['Logradouro']}\")\n",
    "        print(f\"  ‚Ä¢ M√©dia pessoas: {top1['M√©dia pessoas']:.2f}\")\n",
    "        print(f\"  ‚Ä¢ Manh√£: {top1['Manh√£']:.2f} | Tarde: {top1['Tarde']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì AN√ÅLISE CONCLU√çDA!\")\n",
    "print(f\"‚úì {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
