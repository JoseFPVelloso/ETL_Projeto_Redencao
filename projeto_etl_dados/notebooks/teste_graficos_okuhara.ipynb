{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0310d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Bibliotecas importadas\n",
      "‚úì An√°lise iniciada em: 10/11/2025 13:05:51\n",
      "\n",
      "================================================================================\n",
      "DEFINIR PER√çODO DO RELAT√ìRIO\n",
      "================================================================================\n",
      "\n",
      "‚úì Per√≠odo selecionado: 01/10/2025 a 31/10/2025\n",
      "\n",
      "================================================================================\n",
      "Per√≠odo: 01/10/2025 a 31/10/2025\n",
      "  ‚Ä¢ Dias: 31\n",
      "  ‚Ä¢ Per√≠odos por dia: 2 (Manh√£ e Tarde)\n",
      "  ‚Ä¢ Total de per√≠odos: 62\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SELE√á√ÉO DO ARQUIVO RAW\n",
      "================================================================================\n",
      "üìÇ Pasta raw: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\data\\raw\n",
      "\n",
      "üìÅ Arquivos dispon√≠veis (mais recentes primeiro):\n",
      "  1. Contagem_diaria_centro - Padronizada.xlsx\n",
      "     Modificado em: 07/11/2025 18:00\n",
      "\n",
      "  2. Contagem di√°ria - Compilado.xlsx\n",
      "     Modificado em: 07/11/2025 11:51\n",
      "\n",
      "  3. CONTAGEM 2025 - CnR.xlsx\n",
      "     Modificado em: 06/11/2025 12:37\n",
      "\n",
      "  4. RelatorioCidadaoVinculado.xlsx\n",
      "     Modificado em: 05/11/2025 16:38\n",
      "\n",
      "  5. CidadaosVinculadosXBeneficios.xlsx\n",
      "     Modificado em: 05/11/2025 10:42\n",
      "\n",
      "  6. Base Okuhara Kohei.xlsx\n",
      "     Modificado em: 21/10/2025 18:54\n",
      "\n",
      "  7. nomes_Abordados.xlsx\n",
      "     Modificado em: 21/10/2025 17:51\n",
      "\n",
      "  8. Base Tablet.xlsx\n",
      "     Modificado em: 21/10/2025 17:48\n",
      "\n",
      "================================================================================\n",
      "‚úì Arquivo selecionado: CONTAGEM 2025 - CnR.xlsx\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CARREGANDO DADOS RAW\n",
      "================================================================================\n",
      "‚úì Arquivo carregado: CONTAGEM 2025 - CnR.xlsx\n",
      "‚úì Total de registros: 1,943\n",
      "\n",
      "Colunas dispon√≠veis:\n",
      "  - Data\n",
      "  - Equipe\n",
      "  - Logradouro\n",
      "  - Per√≠odo\n",
      "  - Quantidade\n",
      "\n",
      "================================================================================\n",
      "PREPARANDO DADOS\n",
      "================================================================================\n",
      "‚úì Campo 'Data' convertido para datetime\n",
      "‚úì Campo 'Quantidade' convertido para num√©rico\n",
      "‚úì Campo 'Logradouro' limpo\n",
      "‚úì Registros preparados: 1,943\n",
      "\n",
      "Regi√µes encontradas:\n",
      "  - Complexo Okuhara Koei (9 logradouros)\n",
      "  - Glic√©rio (2 logradouros)\n",
      "  - Parque Dom Pedro II (2 logradouros)\n",
      "  - Pra√ßa Roosevelt (1 logradouros)\n",
      "\n",
      "Per√≠odos encontrados (originais):\n",
      "  - 10h\n",
      "  - 15h\n",
      "\n",
      "Per√≠odos padronizados:\n",
      "  - Manh√£\n",
      "  - Tarde\n",
      "\n",
      "‚úì Registros ap√≥s limpeza: 1,943\n",
      "\n",
      "================================================================================\n",
      "FILTRANDO PER√çODO\n",
      "================================================================================\n",
      "Data in√≠cio: 2025-10-01\n",
      "Data fim: 2025-10-31\n",
      "Dias no per√≠odo: 31\n",
      "‚úì Registros no per√≠odo: 952\n",
      "  Logradouros √∫nicos: 13\n",
      "  Regi√µes √∫nicas: 3\n",
      "  Per√≠odos √∫nicos: ['Manh√£', 'Tarde']\n",
      "\n",
      "================================================================================\n",
      "CALCULANDO SOMA TOTAL POR REGI√ÉO\n",
      "================================================================================\n",
      "‚úì Regi√µes ordenadas por soma total:\n",
      "  Parque Dom Pedro II: 3,191 pessoas\n",
      "  Complexo Okuhara Koei: 2,746 pessoas\n",
      "  Glic√©rio: 1,472 pessoas\n",
      "\n",
      "================================================================================\n",
      "AGRUPANDO POR REGI√ÉO E LOGRADOURO\n",
      "================================================================================\n",
      "\n",
      "‚úì Calculando m√©dias por per√≠odo para cada logradouro...\n",
      "‚úì Agrupamento conclu√≠do\n",
      "  Total de logradouros: 13\n",
      "  Total de regi√µes: 3\n",
      "\n",
      "================================================================================\n",
      "CRIANDO RANKINGS DE M√âDIA POR REGI√ÉO\n",
      "================================================================================\n",
      "\n",
      "‚úì Regi√£o: Parque Dom Pedro II\n",
      "  Total de logradouros: 2\n",
      "  Maior m√©dia: 42.18\n",
      "  Menor m√©dia: 9.29\n",
      "\n",
      "‚úì Regi√£o: Complexo Okuhara Koei\n",
      "  Total de logradouros: 9\n",
      "  Maior m√©dia: 12.61\n",
      "  Menor m√©dia: 2.71\n",
      "\n",
      "‚úì Regi√£o: Glic√©rio\n",
      "  Total de logradouros: 2\n",
      "  Maior m√©dia: 13.97\n",
      "  Menor m√©dia: 9.77\n",
      "\n",
      "================================================================================\n",
      "CRIANDO ABAS NO EXCEL POR REGI√ÉO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processando Regi√£o: Parque Dom Pedro II\n",
      "================================================================================\n",
      "‚úì Aba 'Rank M√©dia Parque Dom Pedro II' criada (2 logradouros)\n",
      "  [1/2] ‚úì 'Pra√ßa Fernando Costa' (31 dias)\n",
      "  [2/2] ‚úì 'Viaduto Ant√¥nio Nakashima (emba' (31 dias)\n",
      "\n",
      "================================================================================\n",
      "Processando Regi√£o: Complexo Okuhara Koei\n",
      "================================================================================\n",
      "‚úì Aba 'M√©dia Complexo Okuhara Koei' criada (9 logradouros)\n",
      "  [1/9] ‚úì 'Rua Minas Gerais (Antena Grill)' (31 dias)\n",
      "  [2/9] ‚úì 'Viaduto Okuhara- Fitinha (later' (31 dias)\n",
      "  [3/9] ‚úì 'Avenida Paulista' (31 dias)\n",
      "  [4/9] ‚úì 'Rua Vinicius de Moraes (Pens√£o ' (31 dias)\n",
      "  [5/9] ‚úì 'Pra√ßa Dr. Clemente Ferreira (Su' (31 dias)\n",
      "  [6/9] ‚úì 'Avenida Rebou√ßas (Rampa)' (31 dias)\n",
      "  [7/9] ‚úì 'Pra√ßa Jos√© Molina (Floresta)' (31 dias)\n",
      "  [8/9] ‚úì 'Rua P. Enerst Marcus' (31 dias)\n",
      "  [9/9] ‚úì 'Avenida Pacaembu - Tunel Noite ' (31 dias)\n",
      "\n",
      "================================================================================\n",
      "Processando Regi√£o: Glic√©rio\n",
      "================================================================================\n",
      "‚úì Aba 'Rank M√©dia Glic√©rio' criada (2 logradouros)\n",
      "  [1/2] ‚úì 'Avenida Prefeito Passos, 200' (31 dias)\n",
      "  [2/2] ‚úì 'Rua Ant√¥nio de S√° - bosque urba' (31 dias)\n",
      "\n",
      "================================================================================\n",
      "‚úì Arquivo criado: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\top10_raw_analise_por_regiao.xlsx\n",
      "  Total de abas criadas: 16\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESUMO EXECUTIVO\n",
      "================================================================================\n",
      "\n",
      "AN√ÅLISE: RANKINGS POR REGI√ÉO (VERS√ÉO RAW)\n",
      "\n",
      "ARQUIVO ANALISADO:\n",
      "- CONTAGEM 2025 - CnR.xlsx\n",
      "\n",
      "PER√çODO:\n",
      "- De: 01/10/2025\n",
      "- At√©: 31/10/2025\n",
      "- Total de dias: 31\n",
      "- Total de per√≠odos: 62 (31 dias √ó 2 per√≠odos)\n",
      "\n",
      "METODOLOGIA:\n",
      "- Fonte: Planilha RAW (data/raw)\n",
      "- Estrutura: Data, Equipe, Logradouro, Per√≠odo, Quantidade\n",
      "- Per√≠odos: 10h (Manh√£) e 15h (Tarde)\n",
      "- Extra√ß√£o de Regi√£o: Tudo antes do primeiro \" - \"\n",
      "- Agrupamento: Por Regi√£o e depois por Logradouro\n",
      "- Ordena√ß√£o das Regi√µes: Por soma total de pessoas (decrescente)\n",
      "\n",
      "C√ÅLCULOS:\n",
      "- Soma pessoas: Soma de Quantidade de todos os per√≠odos\n",
      "- M√©dia pessoas: Soma pessoas √∑ 62 per√≠odos\n",
      "- M√©dia por per√≠odo: Soma do per√≠odo √∑ 31 dias\n",
      "\n",
      "DADOS PROCESSADOS:\n",
      "- Registros totais no per√≠odo: 952\n",
      "- Regi√µes encontradas: 3\n",
      "- Logradouros √∫nicos: 13\n",
      "\n",
      "RESUMO POR REGI√ÉO:\n",
      "\n",
      "  ‚Ä¢ Parque Dom Pedro II:\n",
      "    - Logradouros: 2\n",
      "    - Soma total: 3,191 pessoas\n",
      "\n",
      "  ‚Ä¢ Complexo Okuhara Koei:\n",
      "    - Logradouros: 9\n",
      "    - Soma total: 2,746 pessoas\n",
      "\n",
      "  ‚Ä¢ Glic√©rio:\n",
      "    - Logradouros: 2\n",
      "    - Soma total: 1,472 pessoas\n",
      "\n",
      "ARQUIVO GERADO:\n",
      "‚úì c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\top10_raw_analise_por_regiao.xlsx\n",
      "\n",
      "ESTRUTURA DAS ABAS:\n",
      "Para cada regi√£o (ordenadas por soma total):\n",
      "  1. Rank M√©dia [Regi√£o] - Todos os logradouros ordenados por m√©dia\n",
      "  2. Abas individuais de cada logradouro (na ordem do rank, com TODAS as datas)\n",
      "\n",
      "REGI√ÉO COM MAIOR SOMA TOTAL:\n",
      "- Regi√£o: Parque Dom Pedro II\n",
      "- Soma total: 3,191 pessoas\n",
      "- Logradouros: 2\n",
      "\n",
      "\n",
      "TOP 1 DE CADA REGI√ÉO (POR M√âDIA):\n",
      "================================================================================\n",
      "\n",
      "Parque Dom Pedro II:\n",
      "  ‚Ä¢ Logradouro: Parque Dom Pedro II - Pra√ßa Fernando Costa\n",
      "  ‚Ä¢ M√©dia pessoas: 42.18\n",
      "  ‚Ä¢ Manh√£: 44.35 | Tarde: 40.00\n",
      "\n",
      "Complexo Okuhara Koei:\n",
      "  ‚Ä¢ Logradouro: Complexo Okuhara Koei - Rua Minas Gerais (Antena Grill)\n",
      "  ‚Ä¢ M√©dia pessoas: 12.61\n",
      "  ‚Ä¢ Manh√£: 11.68 | Tarde: 13.55\n",
      "\n",
      "Glic√©rio:\n",
      "  ‚Ä¢ Logradouro: Glic√©rio - Avenida Prefeito Passos, 200\n",
      "  ‚Ä¢ M√©dia pessoas: 13.97\n",
      "  ‚Ä¢ Manh√£: 14.71 | Tarde: 13.23\n",
      "\n",
      "================================================================================\n",
      "‚úì AN√ÅLISE CONCLU√çDA!\n",
      "‚úì 10/11/2025 13:05:59\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GERANDO GR√ÅFICOS DE EVOLU√á√ÉO TEMPORAL\n",
      "================================================================================\n",
      "üìÅ Pasta principal: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\graficos\n",
      "üìÅ Pasta complexo: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\graficos\\complexo_okuhara\n",
      "üìÅ Pasta individuais: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\graficos\\complexo_okuhara\\logradouros_individuais\n",
      "üìÅ Pasta regi√µes: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\graficos\\complexo_okuhara\\regioes\n",
      "‚úì Fun√ß√µes auxiliares definidas\n",
      "\n",
      "================================================================================\n",
      "CALCULANDO VALOR M√ÅXIMO GLOBAL (GR√ÅFICOS INDIVIDUAIS)\n",
      "================================================================================\n",
      "‚úì Valor m√°ximo global (individuais): 74\n",
      "  Este ser√° o limite superior do eixo Y em todos os gr√°ficos individuais\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CALCULANDO VALOR M√ÅXIMO GLOBAL (GR√ÅFICOS DE REGI√ïES)\n",
      "================================================================================\n",
      "‚úì Valor m√°ximo global (regi√µes): 48\n",
      "  Este ser√° o limite superior do eixo X em todos os gr√°ficos de regi√µes\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GERANDO GR√ÅFICOS INDIVIDUAIS POR LOGRADOURO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìä Regi√£o: Parque Dom Pedro II\n",
      "================================================================================\n",
      "  [1/2] ‚úì Pra√ßa Fernando Costa\n",
      "  [2/2] ‚úì Viaduto Ant√¥nio Nakashima (embaixo do viaduto/quadrado)\n",
      "\n",
      "================================================================================\n",
      "üìä Regi√£o: Complexo Okuhara Koei\n",
      "================================================================================\n",
      "  [1/9] ‚úì Rua Minas Gerais (Antena Grill)\n",
      "  [2/9] ‚úì Viaduto Okuhara: Fitinha (lateral baixo viaduto)\n",
      "  [3/9] ‚úì Avenida Paulista\n",
      "  [4/9] ‚úì Rua Vinicius de Moraes (Pens√£o do Gerson)\n",
      "  [5/9] ‚úì Pra√ßa Dr. Clemente Ferreira (Subida da Rebou√ßas p/ Dr Arnald\n",
      "  [6/9] ‚úì Avenida Rebou√ßas (Rampa)\n",
      "  [7/9] ‚úì Pra√ßa Jos√© Molina (Floresta)\n",
      "  [8/9] ‚úì Rua P. Enerst Marcus\n",
      "  [9/9] ‚úì Avenida Pacaembu - Tunel Noite Ilustrada\n",
      "\n",
      "================================================================================\n",
      "üìä Regi√£o: Glic√©rio\n",
      "================================================================================\n",
      "  [1/2] ‚úì Avenida Prefeito Passos, 200\n",
      "  [2/2] ‚úì Rua Ant√¥nio de S√° - bosque urbano bem-te-vi (eco ponto)\n",
      "\n",
      "================================================================================\n",
      "‚úì Total de gr√°ficos individuais gerados: 13\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GERANDO GR√ÅFICOS DE M√âDIAS POR REGI√ÉO\n",
      "================================================================================\n",
      "\n",
      "üìä Gerando gr√°fico: Parque Dom Pedro II\n",
      "  ‚úì Salvo: media_periodos_Parque_Dom_Pedro_II.png\n",
      "  ‚úì Logradouros no gr√°fico: 2\n",
      "\n",
      "üìä Gerando gr√°fico: Complexo Okuhara Koei\n",
      "  ‚úì Salvo: media_periodos_Complexo_Okuhara_Koei.png\n",
      "  ‚úì Logradouros no gr√°fico: 9\n",
      "\n",
      "üìä Gerando gr√°fico: Glic√©rio\n",
      "  ‚úì Salvo: media_periodos_Glic√©rio.png\n",
      "  ‚úì Logradouros no gr√°fico: 2\n",
      "\n",
      "================================================================================\n",
      "‚úì Total de gr√°ficos de regi√£o gerados: 3\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GERANDO GR√ÅFICO CONSOLIDADO - VIS√ÉO GERAL\n",
      "================================================================================\n",
      "‚úì Gr√°fico consolidado salvo: top10_consolidado_periodos.png\n",
      "‚úì Localiza√ß√£o: c:\\Users\\x504693\\Documents\\projetos\\projeto_etl_dados\\docs\\graficos\\complexo_okuhara\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESUMO - GR√ÅFICOS GERADOS\n",
      "================================================================================\n",
      "\n",
      "üìä GR√ÅFICOS DE EVOLU√á√ÉO TEMPORAL\n",
      "\n",
      "ESTRUTURA DE PASTAS:\n",
      "  üìÅ graficos/\n",
      "      - complexo_okuhara/\n",
      "          - top10_consolidado_periodos.png\n",
      "          - logradouros_individuais/\n",
      "          - regioes/\n",
      "\n",
      "TOTAIS GERADOS:\n",
      "  ‚Ä¢ Gr√°ficos individuais (evolu√ß√£o temporal): 13\n",
      "    - Linhas de evolu√ß√£o di√°ria (Manh√£ e Tarde)\n",
      "    - Linhas de tend√™ncia com varia√ß√£o absoluta no eixo Y\n",
      "    - Estat√≠sticas (m√©dia, m√°x, m√≠n)\n",
      "    - Eixos padronizados (0 a 74)\n",
      "    - R√≥tulos com valores inteiros em todas as linhas\n",
      "\n",
      "  ‚Ä¢ Gr√°ficos por regi√£o (m√©dias): 3\n",
      "    - Barras horizontais comparando Manh√£ vs Tarde\n",
      "    - Top 15 logradouros de cada regi√£o\n",
      "    - Nomes completos dos logradouros\n",
      "    - Eixos padronizados (0 a 48)\n",
      "    - R√≥tulos com valores inteiros em todas as barras\n",
      "\n",
      "  ‚Ä¢ Gr√°fico consolidado: 1\n",
      "    - Top 10 geral com m√©dias por per√≠odo\n",
      "    - Nomes completos dos logradouros\n",
      "    - R√≥tulos com valores inteiros em todas as barras\n",
      "\n",
      "TOTAL: 17 gr√°ficos\n",
      "\n",
      "CARACTER√çSTICAS:\n",
      "  ‚úì Resolu√ß√£o: 300 DPI (alta qualidade)\n",
      "  ‚úì Per√≠odo analisado: 01/10/2025 a 31/10/2025\n",
      "  ‚úì Total de dias: 31\n",
      "  ‚úì Total de per√≠odos: 62\n",
      "  ‚úì Linhas de tend√™ncia com varia√ß√£o absoluta (diferen√ßa no eixo Y)\n",
      "  ‚úì Estat√≠sticas descritivas em cada gr√°fico individual\n",
      "  ‚úì Eixos padronizados (individuais e regi√µes)\n",
      "  ‚úì Valores inteiros em todos os r√≥tulos de dados\n",
      "  ‚úì Legendas centralizadas abaixo dos gr√°ficos\n",
      "  ‚úì Nomes completos dos logradouros em todos os gr√°ficos\n",
      "  ‚úì Nomes de arqueres sem caracteres problem√°ticos\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚úì GERA√á√ÉO DE GR√ÅFICOS CONCLU√çDA!\n",
      "‚úì 10/11/2025 13:06:18\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# An√°lise dos 10 Logradouros - VERS√ÉO RAW COM GR√ÅFICOS\n",
    "# Base: Planilha RAW (data/raw)\n",
    "# Estrutura: Data, Equipe, Logradouro, Per√≠odo, Quantidade\n",
    "# Per√≠odos: 10h (Manh√£) e 15h (Tarde)\n",
    "# Per√≠odo: Solicitado ao usu√°rio\n",
    "\n",
    "# %% [markdown]\n",
    "# # 1. Configura√ß√£o Inicial\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo dos gr√°ficos\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas\")\n",
    "print(f\"‚úì An√°lise iniciada em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 2. Definir Per√≠odo de An√°lise\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEFINIR PER√çODO DO RELAT√ìRIO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "data_inicio_str = input(\"\\nDigite a DATA INICIAL (dd/mm/aaaa): \")\n",
    "data_fim_str = input(\"Digite a DATA FINAL (dd/mm/aaaa): \")\n",
    "\n",
    "# Converter datas\n",
    "try:\n",
    "    data_inicio_dt = datetime.strptime(data_inicio_str, \"%d/%m/%Y\")\n",
    "    data_fim_dt = datetime.strptime(data_fim_str, \"%d/%m/%Y\")\n",
    "    \n",
    "    # Converter para formato string usado nos filtros\n",
    "    data_inicio = data_inicio_dt.strftime('%Y-%m-%d')\n",
    "    data_fim = data_fim_dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"\\n‚úì Per√≠odo selecionado: {data_inicio_dt.strftime('%d/%m/%Y')} a {data_fim_dt.strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    # Calcular quantidade de dias\n",
    "    dias_periodo = (data_fim_dt - data_inicio_dt).days + 1\n",
    "    total_periodos = dias_periodo * 2  # 2 per√≠odos por dia (Manh√£ e Tarde)\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Per√≠odo: {data_inicio_dt.strftime('%d/%m/%Y')} a {data_fim_dt.strftime('%d/%m/%Y')}\")\n",
    "    print(f\"  ‚Ä¢ Dias: {dias_periodo}\")\n",
    "    print(f\"  ‚Ä¢ Per√≠odos por dia: 2 (Manh√£ e Tarde)\")\n",
    "    print(f\"  ‚Ä¢ Total de per√≠odos: {total_periodos}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "except ValueError:\n",
    "    print(\"‚ùå Formato de data inv√°lido! Use dd/mm/aaaa\")\n",
    "    raise Exception(\"Formato de data inv√°lido\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 3. Selecionar Arquivo RAW\n",
    "\n",
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SELE√á√ÉO DO ARQUIVO RAW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detectar raiz do projeto\n",
    "script_dir = Path(__file__).parent if '__file__' in globals() else Path.cwd()\n",
    "if script_dir.name == 'notebooks':\n",
    "    project_root = script_dir.parent\n",
    "elif script_dir.name == 'etl':\n",
    "    project_root = script_dir.parent.parent\n",
    "else:\n",
    "    project_root = script_dir\n",
    "\n",
    "pasta_raw = project_root / 'data' / 'raw'\n",
    "print(f\"üìÇ Pasta raw: {pasta_raw}\")\n",
    "\n",
    "# Listar arquivos dispon√≠veis\n",
    "arquivos_disponiveis = sorted(list(pasta_raw.glob('*.xlsx')), \n",
    "                               key=lambda x: x.stat().st_mtime, \n",
    "                               reverse=True)\n",
    "\n",
    "if arquivos_disponiveis:\n",
    "    print(f\"\\nüìÅ Arquivos dispon√≠veis (mais recentes primeiro):\")\n",
    "    for i, arq in enumerate(arquivos_disponiveis, 1):\n",
    "        modificado = datetime.fromtimestamp(arq.stat().st_mtime).strftime('%d/%m/%Y %H:%M')\n",
    "        print(f\"  {i}. {arq.name}\")\n",
    "        print(f\"     Modificado em: {modificado}\\n\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    selecao = int(input(\"Digite o n√∫mero do arquivo que deseja analisar: \"))\n",
    "    arquivo_selecionado = arquivos_disponiveis[selecao - 1]\n",
    "    print(f\"‚úì Arquivo selecionado: {arquivo_selecionado.name}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Nenhum arquivo .xlsx encontrado em '{pasta_raw}'\")\n",
    "    raise FileNotFoundError(f\"Nenhum arquivo em {pasta_raw}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %% [markdown]\n",
    "# # 4. Carregar Dados RAW\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CARREGANDO DADOS RAW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(arquivo_selecionado)\n",
    "    print(f\"‚úì Arquivo carregado: {arquivo_selecionado.name}\")\n",
    "    print(f\"‚úì Total de registros: {len(df):,}\")\n",
    "    print(f\"\\nColunas dispon√≠veis:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Verificar campos necess√°rios\n",
    "    campos_necessarios = ['Data', 'Logradouro', 'Per√≠odo', 'Quantidade']\n",
    "    campos_faltando = [c for c in campos_necessarios if c not in df.columns]\n",
    "    \n",
    "    if campos_faltando:\n",
    "        print(f\"\\n‚úó ERRO: Campos faltando: {campos_faltando}\")\n",
    "        raise KeyError(\"Campos necess√°rios n√£o encontrados\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó ERRO ao carregar arquivo: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# %% [markdown]\n",
    "# # 5. Preparar Dados\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREPARANDO DADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Converter data\n",
    "df['Data'] = pd.to_datetime(df['Data'], errors='coerce')\n",
    "\n",
    "# Garantir que Quantidade seja num√©rico\n",
    "df['Quantidade'] = pd.to_numeric(df['Quantidade'], errors='coerce').fillna(0)\n",
    "\n",
    "# Limpar espa√ßos em branco no Logradouro e Per√≠odo\n",
    "df['Logradouro'] = df['Logradouro'].astype(str).str.strip()\n",
    "df['Per√≠odo'] = df['Per√≠odo'].astype(str).str.strip()\n",
    "\n",
    "print(f\"‚úì Campo 'Data' convertido para datetime\")\n",
    "print(f\"‚úì Campo 'Quantidade' convertido para num√©rico\")\n",
    "print(f\"‚úì Campo 'Logradouro' limpo\")\n",
    "print(f\"‚úì Registros preparados: {len(df):,}\")\n",
    "\n",
    "# Extrair regi√£o do logradouro (tudo antes do primeiro \" - \")\n",
    "df['Regi√£o'] = df['Logradouro'].str.split(' - ', n=1).str[0].str.strip()\n",
    "\n",
    "print(f\"\\nRegi√µes encontradas:\")\n",
    "regioes_unicas = sorted(df['Regi√£o'].unique())\n",
    "for regiao in regioes_unicas:\n",
    "    qtd_log = df[df['Regi√£o'] == regiao]['Logradouro'].nunique()\n",
    "    print(f\"  - {regiao} ({qtd_log} logradouros)\")\n",
    "\n",
    "# Verificar per√≠odos √∫nicos ANTES do mapeamento\n",
    "print(f\"\\nPer√≠odos encontrados (originais):\")\n",
    "for periodo in sorted(df['Per√≠odo'].unique()):\n",
    "    print(f\"  - {periodo}\")\n",
    "\n",
    "# Mapear per√≠odos: 10h ‚Üí Manh√£, 15h ‚Üí Tarde\n",
    "mapeamento_periodos = {\n",
    "    '10h': 'Manh√£',\n",
    "    '15h': 'Tarde'\n",
    "}\n",
    "\n",
    "df['Per√≠odo_padrao'] = df['Per√≠odo'].map(mapeamento_periodos)\n",
    "\n",
    "# Verificar se h√° per√≠odos n√£o mapeados\n",
    "periodos_nao_mapeados = df[df['Per√≠odo_padrao'].isna()]['Per√≠odo'].unique()\n",
    "if len(periodos_nao_mapeados) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è ATEN√á√ÉO: Per√≠odos n√£o mapeados encontrados:\")\n",
    "    for periodo in periodos_nao_mapeados:\n",
    "        print(f\"  - '{periodo}'\")\n",
    "    print(f\"\\n   Esses registros ser√£o ignorados na an√°lise.\")\n",
    "    # Remover registros n√£o mapeados\n",
    "    df = df[df['Per√≠odo_padrao'].notna()].copy()\n",
    "\n",
    "print(f\"\\nPer√≠odos padronizados:\")\n",
    "for periodo in sorted(df['Per√≠odo_padrao'].unique()):\n",
    "    print(f\"  - {periodo}\")\n",
    "\n",
    "print(f\"\\n‚úì Registros ap√≥s limpeza: {len(df):,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 6. Filtrar Per√≠odo\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILTRANDO PER√çODO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filtrar per√≠odo\n",
    "df_periodo = df[\n",
    "    (df['Data'] >= data_inicio) & \n",
    "    (df['Data'] <= data_fim)\n",
    "].copy()\n",
    "\n",
    "print(f\"Data in√≠cio: {data_inicio}\")\n",
    "print(f\"Data fim: {data_fim}\")\n",
    "print(f\"Dias no per√≠odo: {dias_periodo}\")\n",
    "print(f\"‚úì Registros no per√≠odo: {len(df_periodo):,}\")\n",
    "print(f\"  Logradouros √∫nicos: {df_periodo['Logradouro'].nunique()}\")\n",
    "print(f\"  Regi√µes √∫nicas: {df_periodo['Regi√£o'].nunique()}\")\n",
    "print(f\"  Per√≠odos √∫nicos: {sorted(df_periodo['Per√≠odo_padrao'].unique())}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 7. Calcular Soma Total por Regi√£o (para ordena√ß√£o)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CALCULANDO SOMA TOTAL POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular soma total de pessoas por regi√£o\n",
    "soma_por_regiao = df_periodo.groupby('Regi√£o')['Quantidade'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(f\"‚úì Regi√µes ordenadas por soma total:\")\n",
    "for regiao, soma in soma_por_regiao.items():\n",
    "    print(f\"  {regiao}: {soma:,.0f} pessoas\")\n",
    "\n",
    "# Lista ordenada de regi√µes (ser√° usada para ordenar as abas)\n",
    "regioes_ordenadas = soma_por_regiao.index.tolist()\n",
    "\n",
    "# %% [markdown]\n",
    "# # 8. Agrupar por Regi√£o e Logradouro\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AGRUPANDO POR REGI√ÉO E LOGRADOURO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Agrupar por Regi√£o e Logradouro\n",
    "df_agrupado = df_periodo.groupby(['Regi√£o', 'Logradouro']).agg({\n",
    "    'Quantidade': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Renomear coluna\n",
    "df_agrupado.rename(columns={'Quantidade': 'Soma pessoas'}, inplace=True)\n",
    "\n",
    "# Calcular M√©dia pessoas (soma / total de per√≠odos)\n",
    "df_agrupado['M√©dia pessoas'] = df_agrupado['Soma pessoas'] / total_periodos\n",
    "\n",
    "# Para cada logradouro, calcular m√©dia por per√≠odo\n",
    "print(\"\\n‚úì Calculando m√©dias por per√≠odo para cada logradouro...\")\n",
    "\n",
    "medias_lista = []\n",
    "\n",
    "for idx, row in df_agrupado.iterrows():\n",
    "    regiao = row['Regi√£o']\n",
    "    logradouro = row['Logradouro']\n",
    "    \n",
    "    # Filtrar dados desse logradouro\n",
    "    df_log = df_periodo[df_periodo['Logradouro'] == logradouro].copy()\n",
    "    \n",
    "    # Agrupar por per√≠odo e somar\n",
    "    soma_por_periodo = df_log.groupby('Per√≠odo_padrao')['Quantidade'].sum()\n",
    "    \n",
    "    # Calcular m√©dia (dividir pela quantidade de dias)\n",
    "    media_manha = soma_por_periodo.get('Manh√£', 0) / dias_periodo\n",
    "    media_tarde = soma_por_periodo.get('Tarde', 0) / dias_periodo\n",
    "    \n",
    "    medias_lista.append({\n",
    "        'Regi√£o': regiao,\n",
    "        'Logradouro': logradouro,\n",
    "        'Soma pessoas': row['Soma pessoas'],\n",
    "        'M√©dia pessoas': row['M√©dia pessoas'],\n",
    "        'Manh√£': media_manha,\n",
    "        'Tarde': media_tarde\n",
    "    })\n",
    "\n",
    "df_completo = pd.DataFrame(medias_lista)\n",
    "\n",
    "print(f\"‚úì Agrupamento conclu√≠do\")\n",
    "print(f\"  Total de logradouros: {len(df_completo)}\")\n",
    "print(f\"  Total de regi√µes: {df_completo['Regi√£o'].nunique()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 9. Criar Rankings por Regi√£o (M√©dia)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRIANDO RANKINGS DE M√âDIA POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rankings_media = {}\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    df_regiao = df_completo[df_completo['Regi√£o'] == regiao].copy()\n",
    "    \n",
    "    # Ordenar por M√©dia pessoas (decrescente)\n",
    "    df_regiao = df_regiao.sort_values('M√©dia pessoas', ascending=False)\n",
    "    \n",
    "    rankings_media[regiao] = df_regiao\n",
    "    \n",
    "    print(f\"\\n‚úì Regi√£o: {regiao}\")\n",
    "    print(f\"  Total de logradouros: {len(df_regiao)}\")\n",
    "    print(f\"  Maior m√©dia: {df_regiao['M√©dia pessoas'].max():.2f}\")\n",
    "    print(f\"  Menor m√©dia: {df_regiao['M√©dia pessoas'].min():.2f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 10. Criar Abas no Excel\n",
    "\n",
    "# %%\n",
    "def limpar_nome_aba(nome):\n",
    "    \"\"\"Remove caracteres inv√°lidos para nomes de abas do Excel\"\"\"\n",
    "    # Caracteres inv√°lidos no Excel: : \\ / ? * [ ]\n",
    "    caracteres_invalidos = [':', '\\\\', '/', '?', '*', '[', ']']\n",
    "    nome_limpo = nome\n",
    "    for char in caracteres_invalidos:\n",
    "        nome_limpo = nome_limpo.replace(char, '-')\n",
    "    # Limitar a 31 caracteres\n",
    "    return nome_limpo[:31]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRIANDO ABAS NO EXCEL POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Caminho do arquivo de sa√≠da\n",
    "pasta_docs = project_root / 'docs'\n",
    "pasta_docs.mkdir(parents=True, exist_ok=True)\n",
    "output_file = pasta_docs / 'top10_raw_analise_por_regiao.xlsx'\n",
    "\n",
    "# Criar o arquivo Excel\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    \n",
    "    # Contador de abas para garantir nomes √∫nicos\n",
    "    nomes_abas_usados = {}\n",
    "    \n",
    "    # Para cada regi√£o (ordenadas por soma total)\n",
    "    for regiao in regioes_ordenadas:\n",
    "        \n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Processando Regi√£o: {regiao}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        # 1. ABA: Rank M√©dia [Regi√£o]\n",
    "        df_rank_media = rankings_media[regiao].copy()\n",
    "        df_rank_media_exportar = df_rank_media[[\n",
    "            'Logradouro', \n",
    "            'Soma pessoas', \n",
    "            'M√©dia pessoas',\n",
    "            'Manh√£',\n",
    "            'Tarde'\n",
    "        ]].copy()\n",
    "        df_rank_media_exportar.insert(0, '#', range(1, len(df_rank_media_exportar) + 1))\n",
    "        \n",
    "        # Nome da aba (limitar a 31 caracteres)\n",
    "        nome_aba_media = f\"Rank M√©dia {regiao}\"\n",
    "        if len(nome_aba_media) > 31:\n",
    "            nome_aba_media = f\"M√©dia {regiao}\"[:31]\n",
    "        \n",
    "        # Limpar caracteres inv√°lidos\n",
    "        nome_aba_media = limpar_nome_aba(nome_aba_media)\n",
    "        \n",
    "        # Garantir nome √∫nico\n",
    "        nome_aba_media_final = nome_aba_media\n",
    "        contador = 1\n",
    "        while nome_aba_media_final in nomes_abas_usados:\n",
    "            nome_aba_media_final = f\"{nome_aba_media[:28]}_{contador}\"\n",
    "            contador += 1\n",
    "        nomes_abas_usados[nome_aba_media_final] = True\n",
    "        \n",
    "        df_rank_media_exportar.to_excel(writer, sheet_name=nome_aba_media_final, index=False)\n",
    "        print(f\"‚úì Aba '{nome_aba_media_final}' criada ({len(df_rank_media_exportar)} logradouros)\")\n",
    "        \n",
    "        # 2. ABAS INDIVIDUAIS: Para cada logradouro do Rank M√©dia (NA ORDEM DO RANKING)\n",
    "        logradouros_ordenados = df_rank_media['Logradouro'].tolist()\n",
    "        \n",
    "        for idx, logradouro in enumerate(logradouros_ordenados, 1):\n",
    "            \n",
    "            # Filtrar dados originais para esse logradouro\n",
    "            df_detalhado = df_periodo[\n",
    "                df_periodo['Logradouro'] == logradouro\n",
    "            ].copy()\n",
    "            \n",
    "            # Criar pivot: transformar per√≠odos em colunas\n",
    "            df_pivot = df_detalhado.pivot_table(\n",
    "                index='Data',\n",
    "                columns='Per√≠odo_padrao',\n",
    "                values='Quantidade',\n",
    "                aggfunc='sum',\n",
    "                fill_value=0\n",
    "            ).reset_index()\n",
    "            \n",
    "            # PREENCHER DATAS FALTANTES\n",
    "            # Criar range completo de datas do per√≠odo\n",
    "            data_inicio_dt_range = pd.to_datetime(data_inicio)\n",
    "            data_fim_dt_range = pd.to_datetime(data_fim)\n",
    "            todas_datas = pd.date_range(start=data_inicio_dt_range, end=data_fim_dt_range, freq='D')\n",
    "            \n",
    "            # Criar DataFrame com todas as datas\n",
    "            df_todas_datas = pd.DataFrame({'Data': todas_datas})\n",
    "            \n",
    "            # Fazer merge para incluir datas faltantes\n",
    "            df_pivot = df_todas_datas.merge(df_pivot, on='Data', how='left')\n",
    "            \n",
    "            # Preencher valores faltantes com 0 (colunas de per√≠odo)\n",
    "            colunas_periodo = [col for col in df_pivot.columns if col != 'Data']\n",
    "            df_pivot[colunas_periodo] = df_pivot[colunas_periodo].fillna(0)\n",
    "            \n",
    "            # Garantir que todas as colunas de per√≠odo existam\n",
    "            for periodo in ['Manh√£', 'Tarde']:\n",
    "                if periodo not in df_pivot.columns:\n",
    "                    df_pivot[periodo] = 0\n",
    "            \n",
    "            # Preparar DataFrame para exporta√ß√£o na ordem correta\n",
    "            df_exportar = pd.DataFrame()\n",
    "            df_exportar['Logradouro'] = [logradouro] * len(df_pivot)\n",
    "            df_exportar['Data'] = df_pivot['Data'].dt.strftime('%d/%m/%Y')\n",
    "            df_exportar['Manh√£'] = df_pivot['Manh√£'].astype(int)\n",
    "            df_exportar['Tarde'] = df_pivot['Tarde'].astype(int)\n",
    "            \n",
    "            # Nome da aba (limitado a 31 caracteres)\n",
    "            # Extrair apenas o nome do logradouro (depois do \" - \")\n",
    "            if ' - ' in logradouro:\n",
    "                nome_logr_curto = logradouro.split(' - ', 1)[1]\n",
    "            else:\n",
    "                nome_logr_curto = logradouro\n",
    "            \n",
    "            # Limpar caracteres inv√°lidos\n",
    "            nome_aba = limpar_nome_aba(nome_logr_curto)\n",
    "            \n",
    "            # Garantir nome √∫nico de aba\n",
    "            nome_aba_final = nome_aba\n",
    "            contador = 1\n",
    "            while nome_aba_final in nomes_abas_usados:\n",
    "                sufixo = f\"_{contador}\"\n",
    "                nome_aba_final = nome_aba[:31-len(sufixo)] + sufixo\n",
    "                contador += 1\n",
    "            nomes_abas_usados[nome_aba_final] = True\n",
    "            \n",
    "            # Escrever aba\n",
    "            df_exportar.to_excel(writer, sheet_name=nome_aba_final, index=False)\n",
    "            print(f\"  [{idx}/{len(logradouros_ordenados)}] ‚úì '{nome_aba_final}' ({len(df_exportar)} dias)\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"‚úì Arquivo criado: {output_file}\")\n",
    "print(f\"  Total de abas criadas: {len(nomes_abas_usados)}\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 11. Resumo Executivo\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMO EXECUTIVO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Contar total de logradouros\n",
    "total_logradouros = df_completo['Logradouro'].nunique()\n",
    "total_regioes = len(regioes_ordenadas)\n",
    "\n",
    "# Resumo por regi√£o\n",
    "resumo_regioes = []\n",
    "for regiao in regioes_ordenadas:\n",
    "    qtd_logradouros = len(rankings_media[regiao])\n",
    "    soma_total = soma_por_regiao[regiao]\n",
    "    \n",
    "    resumo_regioes.append(f\"\"\"\n",
    "  ‚Ä¢ {regiao}:\n",
    "    - Logradouros: {qtd_logradouros}\n",
    "    - Soma total: {soma_total:,.0f} pessoas\"\"\")\n",
    "\n",
    "resumo_regioes_str = \"\\n\".join(resumo_regioes)\n",
    "\n",
    "print(f\"\"\"\n",
    "AN√ÅLISE: RANKINGS POR REGI√ÉO (VERS√ÉO RAW)\n",
    "\n",
    "ARQUIVO ANALISADO:\n",
    "- {arquivo_selecionado.name}\n",
    "\n",
    "PER√çODO:\n",
    "- De: {data_inicio_dt.strftime('%d/%m/%Y')}\n",
    "- At√©: {data_fim_dt.strftime('%d/%m/%Y')}\n",
    "- Total de dias: {dias_periodo}\n",
    "- Total de per√≠odos: {total_periodos} ({dias_periodo} dias √ó 2 per√≠odos)\n",
    "\n",
    "METODOLOGIA:\n",
    "- Fonte: Planilha RAW (data/raw)\n",
    "- Estrutura: Data, Equipe, Logradouro, Per√≠odo, Quantidade\n",
    "- Per√≠odos: 10h (Manh√£) e 15h (Tarde)\n",
    "- Extra√ß√£o de Regi√£o: Tudo antes do primeiro \" - \"\n",
    "- Agrupamento: Por Regi√£o e depois por Logradouro\n",
    "- Ordena√ß√£o das Regi√µes: Por soma total de pessoas (decrescente)\n",
    "\n",
    "C√ÅLCULOS:\n",
    "- Soma pessoas: Soma de Quantidade de todos os per√≠odos\n",
    "- M√©dia pessoas: Soma pessoas √∑ {total_periodos} per√≠odos\n",
    "- M√©dia por per√≠odo: Soma do per√≠odo √∑ {dias_periodo} dias\n",
    "\n",
    "DADOS PROCESSADOS:\n",
    "- Registros totais no per√≠odo: {len(df_periodo):,}\n",
    "- Regi√µes encontradas: {total_regioes}\n",
    "- Logradouros √∫nicos: {total_logradouros}\n",
    "\n",
    "RESUMO POR REGI√ÉO:\n",
    "{resumo_regioes_str}\n",
    "\n",
    "ARQUIVO GERADO:\n",
    "‚úì {output_file}\n",
    "\n",
    "ESTRUTURA DAS ABAS:\n",
    "Para cada regi√£o (ordenadas por soma total):\n",
    "  1. Rank M√©dia [Regi√£o] - Todos os logradouros ordenados por m√©dia\n",
    "  2. Abas individuais de cada logradouro (na ordem do rank, com TODAS as datas)\n",
    "\n",
    "REGI√ÉO COM MAIOR SOMA TOTAL:\n",
    "- Regi√£o: {regioes_ordenadas[0]}\n",
    "- Soma total: {soma_por_regiao[regioes_ordenadas[0]]:,.0f} pessoas\n",
    "- Logradouros: {len(rankings_media[regioes_ordenadas[0]])}\n",
    "\"\"\")\n",
    "\n",
    "# Top 1 de cada regi√£o\n",
    "print(f\"\\nTOP 1 DE CADA REGI√ÉO (POR M√âDIA):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    df_regiao = rankings_media[regiao]\n",
    "    if len(df_regiao) > 0:\n",
    "        top1 = df_regiao.iloc[0]\n",
    "        print(f\"\\n{regiao}:\")\n",
    "        print(f\"  ‚Ä¢ Logradouro: {top1['Logradouro']}\")\n",
    "        print(f\"  ‚Ä¢ M√©dia pessoas: {top1['M√©dia pessoas']:.2f}\")\n",
    "        print(f\"  ‚Ä¢ Manh√£: {top1['Manh√£']:.2f} | Tarde: {top1['Tarde']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì AN√ÅLISE CONCLU√çDA!\")\n",
    "print(f\"‚úì {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %% [markdown]\n",
    "# # 12. Gera√ß√£o de Gr√°ficos - Evolu√ß√£o Temporal\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GERANDO GR√ÅFICOS DE EVOLU√á√ÉO TEMPORAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Criar pastas para salvar gr√°ficos - ESTRUTURA CORRETA\n",
    "pasta_graficos = project_root / 'docs' / 'graficos'\n",
    "pasta_complexo = pasta_graficos / 'complexo_okuhara'\n",
    "pasta_graficos_individuais = pasta_complexo / 'logradouros_individuais'\n",
    "pasta_graficos_regioes = pasta_complexo / 'regioes'\n",
    "\n",
    "pasta_graficos.mkdir(parents=True, exist_ok=True)\n",
    "pasta_complexo.mkdir(parents=True, exist_ok=True)\n",
    "pasta_graficos_individuais.mkdir(parents=True, exist_ok=True)\n",
    "pasta_graficos_regioes.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Pasta principal: {pasta_graficos}\")\n",
    "print(f\"üìÅ Pasta complexo: {pasta_complexo}\")\n",
    "print(f\"üìÅ Pasta individuais: {pasta_graficos_individuais}\")\n",
    "print(f\"üìÅ Pasta regi√µes: {pasta_graficos_regioes}\")\n",
    "\n",
    "# %%\n",
    "def calcular_tendencia(datas, valores):\n",
    "    \"\"\"\n",
    "    Calcula linha de tend√™ncia linear\n",
    "    Retorna valores da tend√™ncia para plotagem e varia√ß√£o absoluta\n",
    "    \"\"\"\n",
    "    # Converter datas para n√∫meros (dias desde a primeira data)\n",
    "    datas_num = [(d - datas.min()).days for d in datas]\n",
    "    \n",
    "    # Calcular regress√£o linear\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(datas_num, valores)\n",
    "    \n",
    "    # Calcular valores da linha de tend√™ncia\n",
    "    tendencia = [slope * x + intercept for x in datas_num]\n",
    "    \n",
    "    # Calcular varia√ß√£o ABSOLUTA do in√≠cio ao fim (diferen√ßa no eixo Y)\n",
    "    if len(tendencia) > 0:\n",
    "        valor_inicio = tendencia[0]\n",
    "        valor_fim = tendencia[-1]\n",
    "        variacao_absoluta = valor_fim - valor_inicio\n",
    "    else:\n",
    "        variacao_absoluta = 0\n",
    "    \n",
    "    return tendencia, slope, r_value**2, variacao_absoluta\n",
    "\n",
    "def limpar_nome_arquivo(nome):\n",
    "    \"\"\"\n",
    "    Remove caracteres problem√°ticos para nomes de arquivos\n",
    "    \"\"\"\n",
    "    # Caracteres problem√°ticos: : \\ / ? * \" < > |\n",
    "    caracteres_problematicos = [':', '\\\\', '/', '?', '*', '\"', '<', '>', '|']\n",
    "    nome_limpo = nome\n",
    "    for char in caracteres_problematicos:\n",
    "        nome_limpo = nome_limpo.replace(char, '-')\n",
    "    return nome_limpo\n",
    "\n",
    "print(\"‚úì Fun√ß√µes auxiliares definidas\")\n",
    "\n",
    "# %%\n",
    "# CALCULAR VALOR M√ÅXIMO GLOBAL PARA PADRONIZA√á√ÉO DOS EIXOS (INDIVIDUAIS)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CALCULANDO VALOR M√ÅXIMO GLOBAL (GR√ÅFICOS INDIVIDUAIS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Encontrar o maior valor entre todos os logradouros (Manh√£ e Tarde)\n",
    "valor_max_global_individuais = 0\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    logradouros_regiao = rankings_media[regiao]['Logradouro'].tolist()\n",
    "    \n",
    "    for logradouro in logradouros_regiao:\n",
    "        df_log = df_periodo[df_periodo['Logradouro'] == logradouro].copy()\n",
    "        \n",
    "        if len(df_log) > 0:\n",
    "            max_manha = df_log[df_log['Per√≠odo_padrao'] == 'Manh√£']['Quantidade'].max()\n",
    "            max_tarde = df_log[df_log['Per√≠odo_padrao'] == 'Tarde']['Quantidade'].max()\n",
    "            valor_max_logradouro = max(max_manha, max_tarde)\n",
    "            \n",
    "            if valor_max_logradouro > valor_max_global_individuais:\n",
    "                valor_max_global_individuais = valor_max_logradouro\n",
    "\n",
    "# Adicionar margem de 10% para melhor visualiza√ß√£o\n",
    "valor_max_global_individuais = int(valor_max_global_individuais * 1.1)\n",
    "\n",
    "print(f\"‚úì Valor m√°ximo global (individuais): {valor_max_global_individuais}\")\n",
    "print(f\"  Este ser√° o limite superior do eixo Y em todos os gr√°ficos individuais\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %%\n",
    "# CALCULAR VALOR M√ÅXIMO GLOBAL PARA PADRONIZA√á√ÉO DOS EIXOS (REGI√ïES)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CALCULANDO VALOR M√ÅXIMO GLOBAL (GR√ÅFICOS DE REGI√ïES)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Encontrar o maior valor entre todas as m√©dias de regi√µes\n",
    "valor_max_global_regioes = 0\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    df_regiao = rankings_media[regiao].copy()\n",
    "    max_manha = df_regiao['Manh√£'].max()\n",
    "    max_tarde = df_regiao['Tarde'].max()\n",
    "    valor_max_regiao = max(max_manha, max_tarde)\n",
    "    \n",
    "    if valor_max_regiao > valor_max_global_regioes:\n",
    "        valor_max_global_regioes = valor_max_regiao\n",
    "\n",
    "# Arredondar e adicionar margem de 10%\n",
    "valor_max_global_regioes = int(valor_max_global_regioes * 1.1)\n",
    "\n",
    "print(f\"‚úì Valor m√°ximo global (regi√µes): {valor_max_global_regioes}\")\n",
    "print(f\"  Este ser√° o limite superior do eixo X em todos os gr√°ficos de regi√µes\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12.1. Gr√°ficos Individuais de Evolu√ß√£o por Logradouro\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GERANDO GR√ÅFICOS INDIVIDUAIS POR LOGRADOURO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_graficos = 0\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"üìä Regi√£o: {regiao}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    # Pegar logradouros da regi√£o (ordenados por m√©dia)\n",
    "    logradouros_regiao = rankings_media[regiao]['Logradouro'].tolist()\n",
    "    \n",
    "    for idx, logradouro in enumerate(logradouros_regiao, 1):\n",
    "        \n",
    "        # Filtrar dados do logradouro\n",
    "        df_log = df_periodo[df_periodo['Logradouro'] == logradouro].copy()\n",
    "        \n",
    "        # Criar pivot com TODAS as datas do per√≠odo\n",
    "        data_inicio_dt_range = pd.to_datetime(data_inicio)\n",
    "        data_fim_dt_range = pd.to_datetime(data_fim)\n",
    "        todas_datas = pd.date_range(start=data_inicio_dt_range, end=data_fim_dt_range, freq='D')\n",
    "        \n",
    "        df_todas_datas = pd.DataFrame({'Data': todas_datas})\n",
    "        \n",
    "        df_pivot = df_log.pivot_table(\n",
    "            index='Data',\n",
    "            columns='Per√≠odo_padrao',\n",
    "            values='Quantidade',\n",
    "            aggfunc='sum',\n",
    "            fill_value=0\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Merge para incluir todas as datas\n",
    "        df_pivot = df_todas_datas.merge(df_pivot, on='Data', how='left')\n",
    "        \n",
    "        # Preencher valores faltantes com 0\n",
    "        for periodo in ['Manh√£', 'Tarde']:\n",
    "            if periodo not in df_pivot.columns:\n",
    "                df_pivot[periodo] = 0\n",
    "            else:\n",
    "                df_pivot[periodo] = df_pivot[periodo].fillna(0)\n",
    "        \n",
    "        # ARREDONDAR OS DADOS ANTES DE PLOTAR\n",
    "        df_pivot['Manh√£'] = df_pivot['Manh√£'].round(0).astype(int)\n",
    "        df_pivot['Tarde'] = df_pivot['Tarde'].round(0).astype(int)\n",
    "        \n",
    "        # Criar o gr√°fico\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        \n",
    "        # Plotar linhas de dados - NOVAS CORES\n",
    "        line_manha = ax.plot(df_pivot['Data'], df_pivot['Manh√£'], \n",
    "                marker='o', linewidth=2.5, markersize=7, \n",
    "                label='Manh√£ (10h)', color='#76B6FF', alpha=0.9, zorder=3)\n",
    "        \n",
    "        line_tarde = ax.plot(df_pivot['Data'], df_pivot['Tarde'], \n",
    "                marker='s', linewidth=2.5, markersize=7, \n",
    "                label='Tarde (15h)', color='#E67E22', alpha=0.9, zorder=3)\n",
    "        \n",
    "        # Adicionar r√≥tulos de dados nas linhas - NOVAS CORES\n",
    "        for i, (data, valor) in enumerate(zip(df_pivot['Data'], df_pivot['Manh√£'])):\n",
    "            if valor > 0:  # S√≥ mostrar se houver valor\n",
    "                ax.annotate(f'{valor}', \n",
    "                           xy=(data, valor), \n",
    "                           xytext=(0, 8),\n",
    "                           textcoords='offset points',\n",
    "                           ha='center', va='bottom',\n",
    "                           fontsize=8, color='#76B6FF',\n",
    "                           fontweight='bold')\n",
    "        \n",
    "        for i, (data, valor) in enumerate(zip(df_pivot['Data'], df_pivot['Tarde'])):\n",
    "            if valor > 0:  # S√≥ mostrar se houver valor\n",
    "                ax.annotate(f'{valor}', \n",
    "                           xy=(data, valor), \n",
    "                           xytext=(0, -12),\n",
    "                           textcoords='offset points',\n",
    "                           ha='center', va='top',\n",
    "                           fontsize=8, color='#E67E22',\n",
    "                           fontweight='bold')\n",
    "        \n",
    "        # Calcular e plotar linhas de tend√™ncia COM VARIA√á√ÉO ABSOLUTA - NOVAS CORES\n",
    "        tendencia_manha, slope_manha, r2_manha, var_abs_manha = calcular_tendencia(\n",
    "            df_pivot['Data'], df_pivot['Manh√£']\n",
    "        )\n",
    "        tendencia_tarde, slope_tarde, r2_tarde, var_abs_tarde = calcular_tendencia(\n",
    "            df_pivot['Data'], df_pivot['Tarde']\n",
    "        )\n",
    "        \n",
    "        # Formatar texto da varia√ß√£o com sinal\n",
    "        sinal_manha = '+' if var_abs_manha >= 0 else ''\n",
    "        sinal_tarde = '+' if var_abs_tarde >= 0 else ''\n",
    "        \n",
    "        ax.plot(df_pivot['Data'], tendencia_manha, \n",
    "                linestyle='--', linewidth=2, \n",
    "                label=f'Tend√™ncia Manh√£ ({sinal_manha}{var_abs_manha:.1f})', \n",
    "                color='#76B6FF', alpha=0.7, zorder=2)\n",
    "        \n",
    "        ax.plot(df_pivot['Data'], tendencia_tarde, \n",
    "                linestyle='--', linewidth=2, \n",
    "                label=f'Tend√™ncia Tarde ({sinal_tarde}{var_abs_tarde:.1f})', \n",
    "                color='#E67E22', alpha=0.7, zorder=2)\n",
    "        \n",
    "        # PADRONIZAR EIXO Y (0 at√© valor_max_global_individuais)\n",
    "        ax.set_ylim(0, valor_max_global_individuais)\n",
    "        \n",
    "        # Configurar eixos e formata√ß√£o\n",
    "        ax.set_xlabel('Data', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Quantidade de Pessoas', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Extrair nome curto do logradouro\n",
    "        if ' - ' in logradouro:\n",
    "            nome_log_curto = logradouro.split(' - ', 1)[1]\n",
    "        else:\n",
    "            nome_log_curto = logradouro\n",
    "        \n",
    "        ax.set_title(\n",
    "            f'Evolu√ß√£o - {nome_log_curto}\\n'\n",
    "            f'Regi√£o: {regiao} | Per√≠odo: {data_inicio_dt.strftime(\"%d/%m/%Y\")} a {data_fim_dt.strftime(\"%d/%m/%Y\")}',\n",
    "            fontsize=14, fontweight='bold', pad=20\n",
    "        )\n",
    "        \n",
    "        # Formatar eixo X com datas\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, dias_periodo // 15)))\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Grid\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', zorder=1)\n",
    "        \n",
    "        # Legenda CENTRALIZADA ABAIXO DO GR√ÅFICO\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), \n",
    "                 ncol=4, fontsize=10, framealpha=0.9)\n",
    "        \n",
    "        # Adicionar estat√≠sticas no canto\n",
    "        stats_text = (\n",
    "            f'Manh√£: M√©dia={int(df_pivot[\"Manh√£\"].mean())} | '\n",
    "            f'Max={int(df_pivot[\"Manh√£\"].max())} | '\n",
    "            f'Min={int(df_pivot[\"Manh√£\"].min())}\\n'\n",
    "            f'Tarde: M√©dia={int(df_pivot[\"Tarde\"].mean())} | '\n",
    "            f'Max={int(df_pivot[\"Tarde\"].max())} | '\n",
    "            f'Min={int(df_pivot[\"Tarde\"].min())}'\n",
    "        )\n",
    "        ax.text(0.02, 0.98, stats_text, \n",
    "                transform=ax.transAxes, \n",
    "                fontsize=9, \n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        # Ajustar layout para acomodar a legenda\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(bottom=0.15)\n",
    "        \n",
    "        # Salvar gr√°fico com nome limpo (sem caracteres problem√°ticos)\n",
    "        nome_arquivo_limpo = limpar_nome_arquivo(nome_log_curto[:50])\n",
    "        nome_arquivo = f\"{regiao.replace(' ', '_')}_{idx:02d}_{nome_arquivo_limpo}.png\"\n",
    "        caminho_arquivo = pasta_graficos_individuais / nome_arquivo\n",
    "        plt.savefig(caminho_arquivo, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        total_graficos += 1\n",
    "        print(f\"  [{idx}/{len(logradouros_regiao)}] ‚úì {nome_log_curto[:60]}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"‚úì Total de gr√°ficos individuais gerados: {total_graficos}\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12.2. Gr√°ficos de M√©dias por Regi√£o\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GERANDO GR√ÅFICOS DE M√âDIAS POR REGI√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for regiao in regioes_ordenadas:\n",
    "    print(f\"\\nüìä Gerando gr√°fico: {regiao}\")\n",
    "    \n",
    "    # Pegar dados da regi√£o\n",
    "    df_regiao = rankings_media[regiao].copy()\n",
    "    \n",
    "    # ARREDONDAR OS DADOS ANTES DE PLOTAR\n",
    "    df_regiao['Manh√£'] = df_regiao['Manh√£'].round(0).astype(int)\n",
    "    df_regiao['Tarde'] = df_regiao['Tarde'].round(0).astype(int)\n",
    "    \n",
    "    # Limitar aos top 15 para n√£o poluir o gr√°fico (ou todos se forem poucos)\n",
    "    max_logradouros = min(15, len(df_regiao))\n",
    "    df_regiao_plot = df_regiao.head(max_logradouros)\n",
    "    \n",
    "    # Extrair nomes curtos dos logradouros (COMPLETOS)\n",
    "    nomes_curtos = []\n",
    "    for log in df_regiao_plot['Logradouro']:\n",
    "        if ' - ' in log:\n",
    "            nome_curto = log.split(' - ', 1)[1]\n",
    "        else:\n",
    "            nome_curto = log\n",
    "        nomes_curtos.append(nome_curto)\n",
    "    \n",
    "    # Criar figura com altura ajust√°vel\n",
    "    fig, ax = plt.subplots(figsize=(16, max(10, max_logradouros * 0.6)))\n",
    "    \n",
    "    # Preparar dados\n",
    "    x = np.arange(len(df_regiao_plot))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Criar barras agrupadas - NOVAS CORES\n",
    "    bars1 = ax.barh(x - width/2, df_regiao_plot['Manh√£'], width,\n",
    "                    label='Manh√£ (10h)', color='#FF8C00', alpha=0.9)\n",
    "    bars2 = ax.barh(x + width/2, df_regiao_plot['Tarde'], width,\n",
    "                    label='Tarde (15h)', color='#1E90FF', alpha=0.9)\n",
    "    \n",
    "    # Configurar eixos\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(nomes_curtos, fontsize=10)\n",
    "    ax.set_xlabel('M√©dia de Pessoas por Per√≠odo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(\n",
    "        f'M√©dia de Pessoas por Per√≠odo - {regiao}\\n'\n",
    "        f'Per√≠odo: {data_inicio_dt.strftime(\"%d/%m/%Y\")} a {data_fim_dt.strftime(\"%d/%m/%Y\")} '\n",
    "        f'({dias_periodo} dias)',\n",
    "        fontsize=14, fontweight='bold', pad=20\n",
    "    )\n",
    "    \n",
    "    # PADRONIZAR EIXO X (0 at√© valor_max_global_regioes)\n",
    "    ax.set_xlim(0, valor_max_global_regioes)\n",
    "    \n",
    "    # Adicionar r√≥tulos de dados nas barras\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            width_val = bar.get_width()\n",
    "            if width_val > 0:  # S√≥ mostrar se houver valor\n",
    "                ax.text(width_val, bar.get_y() + bar.get_height()/2,\n",
    "                       f' {int(width_val)}',\n",
    "                       va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Inverter eixo Y para ranking crescente\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Grid\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Legenda CENTRALIZADA ABAIXO DO GR√ÅFICO\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.08), \n",
    "             ncol=2, fontsize=11, framealpha=0.9)\n",
    "    \n",
    "    # Ajustar layout para acomodar legenda (SEM NOTA)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.10)\n",
    "    \n",
    "    # Salvar gr√°fico\n",
    "    nome_arquivo = f\"media_periodos_{regiao.replace(' ', '_')}.png\"\n",
    "    caminho_arquivo = pasta_graficos_regioes / nome_arquivo\n",
    "    plt.savefig(caminho_arquivo, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  ‚úì Salvo: {nome_arquivo}\")\n",
    "    print(f\"  ‚úì Logradouros no gr√°fico: {max_logradouros}\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"‚úì Total de gr√°ficos de regi√£o gerados: {len(regioes_ordenadas)}\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12.3. Gr√°fico Consolidado - Vis√£o Geral\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GERANDO GR√ÅFICO CONSOLIDADO - VIS√ÉO GERAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Pegar Top 10 geral\n",
    "top10_geral = df_completo.nlargest(10, 'M√©dia pessoas').copy()\n",
    "\n",
    "# ARREDONDAR OS DADOS ANTES DE PLOTAR\n",
    "top10_geral['Manh√£'] = top10_geral['Manh√£'].round(0).astype(int)\n",
    "top10_geral['Tarde'] = top10_geral['Tarde'].round(0).astype(int)\n",
    "\n",
    "# Criar figura\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Preparar dados - NOMES COMPLETOS\n",
    "nomes_completos = []\n",
    "for log in top10_geral['Logradouro']:\n",
    "    if ' - ' in log:\n",
    "        nome = log.split(' - ', 1)[1]  # Pegar s√≥ depois do \" - \"\n",
    "    else:\n",
    "        nome = log\n",
    "    nomes_completos.append(nome)\n",
    "\n",
    "x = np.arange(len(top10_geral))\n",
    "width = 0.35\n",
    "\n",
    "# Criar barras - NOVAS CORES\n",
    "bars1 = ax.barh(x - width/2, top10_geral['Manh√£'], width,\n",
    "                label='Manh√£ (10h)', color='#FF8C00', alpha=0.9)\n",
    "bars2 = ax.barh(x + width/2, top10_geral['Tarde'], width,\n",
    "                label='Tarde (15h)', color='#1E90FF', alpha=0.9)\n",
    "\n",
    "# Configurar\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(nomes_completos, fontsize=11)\n",
    "ax.set_xlabel('M√©dia de Pessoas por Per√≠odo', fontsize=13, fontweight='bold')\n",
    "ax.set_title(\n",
    "    f'Top 10 Logradouros - M√©dia de Pessoas por Per√≠odo (Consolidado)\\n'\n",
    "    f'Per√≠odo: {data_inicio_dt.strftime(\"%d/%m/%Y\")} a {data_fim_dt.strftime(\"%d/%m/%Y\")} '\n",
    "    f'({dias_periodo} dias, {total_periodos} per√≠odos)',\n",
    "    fontsize=15, fontweight='bold', pad=20\n",
    ")\n",
    "\n",
    "# Adicionar r√≥tulos de dados nas barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        width_val = bar.get_width()\n",
    "        if width_val > 0:\n",
    "            ax.text(width_val, bar.get_y() + bar.get_height()/2,\n",
    "                   f' {int(width_val)}',\n",
    "                   va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Inverter eixo Y\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Grid\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Legenda CENTRALIZADA ABAIXO DO GR√ÅFICO\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.08), \n",
    "         ncol=2, fontsize=12, framealpha=0.9)\n",
    "\n",
    "# Ajustar layout para acomodar legenda\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.10)\n",
    "\n",
    "# Salvar NO COMPLEXO_OKUHARA\n",
    "caminho_consolidado = pasta_complexo / 'top10_consolidado_periodos.png'\n",
    "plt.savefig(caminho_consolidado, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úì Gr√°fico consolidado salvo: top10_consolidado_periodos.png\")\n",
    "print(f\"‚úì Localiza√ß√£o: {pasta_complexo}\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12.4. Resumo dos Gr√°ficos Gerados\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMO - GR√ÅFICOS GERADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_individuais = len(list(pasta_graficos_individuais.glob('*.png')))\n",
    "total_regioes = len(list(pasta_graficos_regioes.glob('*.png')))\n",
    "total_consolidado = len(list(pasta_complexo.glob('*.png')))\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä GR√ÅFICOS DE EVOLU√á√ÉO TEMPORAL\n",
    "\n",
    "ESTRUTURA DE PASTAS:\n",
    "  üìÅ graficos/\n",
    "      - complexo_okuhara/\n",
    "          - top10_consolidado_periodos.png\n",
    "          - logradouros_individuais/\n",
    "          - regioes/\n",
    "\n",
    "TOTAIS GERADOS:\n",
    "  ‚Ä¢ Gr√°ficos individuais (evolu√ß√£o temporal): {total_individuais}\n",
    "    - Linhas de evolu√ß√£o di√°ria (Manh√£ e Tarde)\n",
    "    - Linhas de tend√™ncia com varia√ß√£o absoluta no eixo Y\n",
    "    - Estat√≠sticas (m√©dia, m√°x, m√≠n)\n",
    "    - Eixos padronizados (0 a {valor_max_global_individuais})\n",
    "    - R√≥tulos com valores inteiros em todas as linhas\n",
    "  \n",
    "  ‚Ä¢ Gr√°ficos por regi√£o (m√©dias): {total_regioes}\n",
    "    - Barras horizontais comparando Manh√£ vs Tarde\n",
    "    - Top 15 logradouros de cada regi√£o\n",
    "    - Nomes completos dos logradouros\n",
    "    - Eixos padronizados (0 a {valor_max_global_regioes})\n",
    "    - R√≥tulos com valores inteiros em todas as barras\n",
    "  \n",
    "  ‚Ä¢ Gr√°fico consolidado: {total_consolidado}\n",
    "    - Top 10 geral com m√©dias por per√≠odo\n",
    "    - Nomes completos dos logradouros\n",
    "    - R√≥tulos com valores inteiros em todas as barras\n",
    "\n",
    "TOTAL: {total_individuais + total_regioes + total_consolidado} gr√°ficos\n",
    "\n",
    "CARACTER√çSTICAS:\n",
    "  ‚úì Resolu√ß√£o: 300 DPI (alta qualidade)\n",
    "  ‚úì Per√≠odo analisado: {data_inicio_dt.strftime('%d/%m/%Y')} a {data_fim_dt.strftime('%d/%m/%Y')}\n",
    "  ‚úì Total de dias: {dias_periodo}\n",
    "  ‚úì Total de per√≠odos: {total_periodos}\n",
    "  ‚úì Linhas de tend√™ncia com varia√ß√£o absoluta (diferen√ßa no eixo Y)\n",
    "  ‚úì Estat√≠sticas descritivas em cada gr√°fico individual\n",
    "  ‚úì Eixos padronizados (individuais e regi√µes)\n",
    "  ‚úì Valores inteiros em todos os r√≥tulos de dados\n",
    "  ‚úì Legendas centralizadas abaixo dos gr√°ficos\n",
    "  ‚úì Nomes completos dos logradouros em todos os gr√°ficos\n",
    "  ‚úì Nomes de arqueres sem caracteres problem√°ticos\n",
    "\n",
    "\"\"\")\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úì GERA√á√ÉO DE GR√ÅFICOS CONCLU√çDA!\")\n",
    "print(f\"‚úì {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
